{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning Numeric Columns\n",
    "\n",
    "When grouping, numeric columns are often used as the aggregating column and not the grouping column. In this chapter, we'll learn how to bin numeric columns into specific groups using the `cut` and `qcut` **functions** (not methods). After binning, we'll be able to more easily use them for grouping. Let's begin with the housing dataset, which has a few numeric columns that make sense to bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CollgCr</td>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>PConc</td>\n",
       "      <td>1710</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veenker</td>\n",
       "      <td>6</td>\n",
       "      <td>1976</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>1262</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CollgCr</td>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>PConc</td>\n",
       "      <td>1786</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Crawfor</td>\n",
       "      <td>7</td>\n",
       "      <td>1915</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>1717</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoRidge</td>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>PConc</td>\n",
       "      <td>2198</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Neighborhood  OverallQual  YearBuilt Exterior1st Foundation  GrLivArea  \\\n",
       "0      CollgCr            7       2003     VinylSd      PConc       1710   \n",
       "1      Veenker            6       1976     MetalSd     CBlock       1262   \n",
       "2      CollgCr            7       2001     VinylSd      PConc       1786   \n",
       "3      Crawfor            7       1915     Wd Sdng     BrkTil       1717   \n",
       "4      NoRidge            8       2000     VinylSd      PConc       2198   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "usecols = ['Neighborhood', 'OverallQual', 'YearBuilt', 'Exterior1st', \n",
    "           'Foundation', 'GrLivArea', 'SalePrice']\n",
    "df = pd.read_csv('../data/housing.csv', usecols=usecols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with numeric columns\n",
    "\n",
    "Any column regardless of its data type may be used as the grouping column. Although numeric columns are usually used as the aggregating column, there are cases where it is sensible to use them as the grouping column.  Here, we find the median price for the ten unique values of `OverallQual` and also report the total number of houses in the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50150.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51770.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87473.750000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108420.655172</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>133523.347607</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>161603.034759</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>207716.423197</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>274735.535714</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>367513.023256</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>438588.388889</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean  size\n",
       "OverallQual                     \n",
       "1             50150.000000     2\n",
       "2             51770.333333     3\n",
       "3             87473.750000    20\n",
       "4            108420.655172   116\n",
       "5            133523.347607   397\n",
       "6            161603.034759   374\n",
       "7            207716.423197   319\n",
       "8            274735.535714   168\n",
       "9            367513.023256    43\n",
       "10           438588.388889    18"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('OverallQual')['SalePrice'].agg(['mean', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GrLivArea` column is also numeric, but is a poor choice for grouping as there are many unique values. Let's perform the same operation as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>39300.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>60000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>35311.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>68500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>86000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean  size\n",
       "GrLivArea               \n",
       "334        39300.0     1\n",
       "438        60000.0     1\n",
       "480        35311.0     1\n",
       "520        68500.0     1\n",
       "605        86000.0     1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df.groupby('GrLivArea')['SalePrice'].agg(['mean', 'size'])\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first five unique values of `GrLivArea` all appear exactly once. Groups with one observation are usually not that interesting. In fact, the average group size has just 1.7 rows in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.6957026713124275)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp['size'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more than half as many groups as there are rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 861 groups from 1460 total rows.\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {len(df_temp)} groups from {len(df)} total rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning with `pd.cut`\n",
    "\n",
    "The `pd.cut` function provides the machinery for binning numeric columns into a specific number of bins. Pass a numeric Series as the first argument and the boundaries of the bins as the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (1500, 2000]\n",
       "1    (1000, 1500]\n",
       "2    (1500, 2000]\n",
       "3    (1500, 2000]\n",
       "4    (2000, 3000]\n",
       "Name: GrLivArea, dtype: category\n",
       "Categories (6, interval[int64, right]): [(0, 500] < (500, 1000] < (1000, 1500] < (1500, 2000] < (2000, 3000] < (3000, 10000]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = pd.cut(df['GrLivArea'], bins=[0, 500, 1000, 1500, 2000, 3000, 10_000])\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ordered categorical Series will be returned with one category less than the number of boundaries given. Each category will be an interval with two endpoints. The left endpoint is **exclusive**, while the right is **inclusive**. For instance, the interval `(1500, 2000]` does not include 1500 exactly, but does include 2000. \n",
    "\n",
    "### Interval data type\n",
    "\n",
    "While the resulting column is categorical, each individual value in the column is an **Interval** object, which is specific to pandas. The `cat` accessor is used to return all six of these Interval categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IntervalIndex([(0, 500], (500, 1000], (1000, 1500], (1500, 2000], (2000, 3000],\n",
       "               (3000, 10000]],\n",
       "              dtype='interval[int64, right]')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single value may be retrieved using integer location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(1000, 1500, closed='right')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.cat.categories[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Must know minimum and maximum value\n",
    "\n",
    "You must know both the minimum and maximum value of the column you are binning to make precise bins around the current data. In this case, 0 is lower than the minimum and 10,000 is much greater than the maximum `GrLivArea` so all values will be placed within a bin. If there are values greater than the last given bin value, then these values will be missing in the returned Series. \n",
    "\n",
    "Now that the data is binned, we can count the number of houses within each of these six categories. Notice how only three houses have `GrLivArea` less than 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea\n",
       "(0, 500]           3\n",
       "(500, 1000]      228\n",
       "(1000, 1500]     554\n",
       "(1500, 2000]     461\n",
       "(2000, 3000]     196\n",
       "(3000, 10000]     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the precise lower and upper boundaries, use the minimum and maximum of the column. You'll also need to set the `include_lowest` parameter to `True` so the very first bin includes the lowest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea\n",
       "(333.999, 500.0]      3\n",
       "(500.0, 1000.0]     228\n",
       "(1000.0, 1500.0]    554\n",
       "(1500.0, 2000.0]    461\n",
       "(2000.0, 3000.0]    196\n",
       "(3000.0, 5642.0]     18\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_min, area_max = df['GrLivArea'].agg(['min', 'max'])\n",
    "s = pd.cut(df['GrLivArea'], bins=[area_min, 500, 1000, 1500, 2000, 3000, area_max],\n",
    "          include_lowest=True)\n",
    "s.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut into a specific number of bins\n",
    "\n",
    "A second way to use `pd.cut` is to supply it a single integer for the number of bins to create. Each bin created will have equal width. Here, we create eight bins on the same column and immediately find the counts of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea\n",
       "(328.692, 997.5]    228\n",
       "(997.5, 1661.0]     740\n",
       "(1661.0, 2324.5]    389\n",
       "(2324.5, 2988.0]     85\n",
       "(2988.0, 3651.5]     14\n",
       "(3651.5, 4315.0]      0\n",
       "(4315.0, 4978.5]      3\n",
       "(4978.5, 5642.0]      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(df['GrLivArea'], bins=8).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take care when setting the `precision` parameter\n",
    "\n",
    "By default, pandas uses up to three digits of precision for creating the bins. You may use the `precision` parameter to set the decimal precision (just like rounding), though care must be taken, as it only affects the boundary value after the cut has taken place. The real boundaries are still the same as above. To show this, we'll set `precision` to -3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea\n",
       "(300.0, 1000.0]     228\n",
       "(1000.0, 1700.0]    740\n",
       "(1700.0, 2300.0]    389\n",
       "(2300.0, 3000.0]     85\n",
       "(3000.0, 3700.0]     14\n",
       "(3700.0, 4300.0]      0\n",
       "(4300.0, 5000.0]      3\n",
       "(5000.0, 5600.0]      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(df['GrLivArea'], bins=8, precision=-3).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting precision to -3 (rounding to the nearest thousand) results in the exact same counts as above. It would appear that the same number of houses (740) have `GrLivArea` greater than 998 up to 1661 as those with `GrLivArea` greater than 1000 up to 1700.\n",
    "\n",
    "The `between` method is used below to determine whether a house has a `GrLivArea` within a certain range. The resulting boolean Series is summed to find the count. Note how the true count below does not match the count produced from `pd.cut` as setting the `precision` parameter only round the boundaries after the cut has been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(740)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['GrLivArea'].between(999, 1661).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(782)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['GrLivArea'].between(1001, 1700).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the bins with string names\n",
    "\n",
    "Each bin may be labeled with a string instead of the interval by setting the `labels` parameter to a list of strings, one for each bin. Here, we create three equal-width bins with three string labels. When using string labels, you won't know the endpoints for the bins unless you return them by setting `retbins` to `True`. Both the Series and the bin boundaries will be returned as a tuple, which we unpack into separate variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     small\n",
       "1     small\n",
       "2     small\n",
       "3     small\n",
       "4    medium\n",
       "Name: GrLivArea, dtype: category\n",
       "Categories (3, object): ['small' < 'medium' < 'large']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, bins = pd.cut(df['GrLivArea'], bins=3, \n",
    "                 labels=['small', 'medium', 'large'], retbins=True)\n",
    "s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bin boundaries are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile binning with `pd.qcut`\n",
    "\n",
    "When we cut our Series into eight equal-width bins, one of the categories had zero observations in it. Instead of using equal-width bins, you may wish to have an equal number of observations in each bin. The `pd.qcut` function bins according to quantiles. You may provide it a list of floats as the quantile boundaries or an integer to create that many bins all with (approximately) equal number of observations in each. Below, we attempt to create eight bins with the same number of observations in each. Because there are duplicate `GrLivArea` values, it may be impossible to create boundaries where each bin has an equal number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea\n",
       "(333.0, 954.0]      184\n",
       "(954.0, 1130.0]     181\n",
       "(1130.0, 1304.0]    183\n",
       "(1304.0, 1464.0]    183\n",
       "(1464.0, 1620.0]    182\n",
       "(1620.0, 1777.0]    182\n",
       "(1777.0, 2079.0]    182\n",
       "(2079.0, 5642.0]    183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df['GrLivArea'], 8, precision=0).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a list of quantiles as the second argument to create bins of a specific size. Here, three bins are created that hold 20%, 70%, and 10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea\n",
       "(333.0, 1067.0]      292\n",
       "(1067.0, 2158.0]    1022\n",
       "(2158.0, 5642.0]     146\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(df['GrLivArea'], [0, 0.2, 0.9, 1], precision=0).value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `quantile` method to verify the bin edge values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     334.0\n",
       "0.2    1066.6\n",
       "0.9    2158.3\n",
       "1.0    5642.0\n",
       "Name: GrLivArea, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['GrLivArea'].quantile([0, 0.2, 0.9, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping with bins\n",
    "\n",
    "Grouping is often more sensible after binning numeric columns that have many unique values. Let's create a new column, `AreaBin`, that cuts `GrLivArea` into five categories each with the same number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>AreaBin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CollgCr</td>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>PConc</td>\n",
       "      <td>1710</td>\n",
       "      <td>208500</td>\n",
       "      <td>(1578.0, 1869.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veenker</td>\n",
       "      <td>6</td>\n",
       "      <td>1976</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>1262</td>\n",
       "      <td>181500</td>\n",
       "      <td>(1066.6, 1339.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CollgCr</td>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>PConc</td>\n",
       "      <td>1786</td>\n",
       "      <td>223500</td>\n",
       "      <td>(1578.0, 1869.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Neighborhood  OverallQual  YearBuilt Exterior1st Foundation  GrLivArea  \\\n",
       "0      CollgCr            7       2003     VinylSd      PConc       1710   \n",
       "1      Veenker            6       1976     MetalSd     CBlock       1262   \n",
       "2      CollgCr            7       2001     VinylSd      PConc       1786   \n",
       "\n",
       "   SalePrice           AreaBin  \n",
       "0     208500  (1578.0, 1869.0]  \n",
       "1     181500  (1066.6, 1339.0]  \n",
       "2     223500  (1578.0, 1869.0]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AreaBin'] = pd.qcut(df['GrLivArea'], 5)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this column like we do any other grouping column and do so below to find the median price for houses in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nealv\\AppData\\Local\\Temp\\ipykernel_42244\\353944606.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df.groupby('AreaBin')['SalePrice'].median().round(-3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AreaBin\n",
       "(333.999, 1066.6]    120000.0\n",
       "(1066.6, 1339.0]     145000.0\n",
       "(1339.0, 1578.0]     174000.0\n",
       "(1578.0, 1869.0]     193000.0\n",
       "(1869.0, 5642.0]     250000.0\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('AreaBin')['SalePrice'].median().round(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we create a pivot table of the median price by `Foundation` and `AreaBin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nealv\\AppData\\Local\\Temp\\ipykernel_42244\\35814611.py:1: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  df.pivot_table(index='Foundation', columns='AreaBin',\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AreaBin</th>\n",
       "      <th>(333.999, 1066.6]</th>\n",
       "      <th>(1066.6, 1339.0]</th>\n",
       "      <th>(1339.0, 1578.0]</th>\n",
       "      <th>(1578.0, 1869.0]</th>\n",
       "      <th>(1869.0, 5642.0]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foundation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BrkTil</th>\n",
       "      <td>88000.0</td>\n",
       "      <td>114000.0</td>\n",
       "      <td>137500.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>189000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBlock</th>\n",
       "      <td>124000.0</td>\n",
       "      <td>141000.0</td>\n",
       "      <td>154000.0</td>\n",
       "      <td>165325.0</td>\n",
       "      <td>216000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PConc</th>\n",
       "      <td>132625.0</td>\n",
       "      <td>164990.0</td>\n",
       "      <td>188750.0</td>\n",
       "      <td>224900.0</td>\n",
       "      <td>280000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slab</th>\n",
       "      <td>88750.0</td>\n",
       "      <td>91500.0</td>\n",
       "      <td>118858.0</td>\n",
       "      <td>127300.0</td>\n",
       "      <td>144000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stone</th>\n",
       "      <td>116000.0</td>\n",
       "      <td>102776.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>201489.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wood</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143000.0</td>\n",
       "      <td>164000.0</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AreaBin     (333.999, 1066.6]  (1066.6, 1339.0]  (1339.0, 1578.0]  \\\n",
       "Foundation                                                          \n",
       "BrkTil                88000.0          114000.0          137500.0   \n",
       "CBlock               124000.0          141000.0          154000.0   \n",
       "PConc                132625.0          164990.0          188750.0   \n",
       "Slab                  88750.0           91500.0          118858.0   \n",
       "Stone                116000.0          102776.0               NaN   \n",
       "Wood                      NaN               NaN          143000.0   \n",
       "\n",
       "AreaBin     (1578.0, 1869.0]  (1869.0, 5642.0]  \n",
       "Foundation                                      \n",
       "BrkTil              140000.0          189000.0  \n",
       "CBlock              165325.0          216000.0  \n",
       "PConc               224900.0          280000.0  \n",
       "Slab                127300.0          144000.0  \n",
       "Stone                    NaN          201489.5  \n",
       "Wood                164000.0          250000.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index='Foundation', columns='AreaBin', \n",
    "               values='SalePrice', aggfunc='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Use the `bikes` DataFrame for the following exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 19:01:00</td>\n",
       "      <td>2013-06-28 19:17:00</td>\n",
       "      <td>993</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Michigan Ave &amp; Oak St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 22:53:00</td>\n",
       "      <td>2013-06-28 23:03:00</td>\n",
       "      <td>623</td>\n",
       "      <td>Clinton St &amp; Washington Blvd</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Wells St &amp; Walton St</td>\n",
       "      <td>19.0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-30 14:43:00</td>\n",
       "      <td>2013-06-30 15:01:00</td>\n",
       "      <td>1040</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Dearborn St &amp; Monroe St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender            starttime             stoptime  tripduration  \\\n",
       "0   Male  2013-06-28 19:01:00  2013-06-28 19:17:00           993   \n",
       "1   Male  2013-06-28 22:53:00  2013-06-28 23:03:00           623   \n",
       "2   Male  2013-06-30 14:43:00  2013-06-30 15:01:00          1040   \n",
       "\n",
       "              from_station_name  start_capacity          to_station_name  \\\n",
       "0     Lake Shore Dr & Monroe St            11.0    Michigan Ave & Oak St   \n",
       "1  Clinton St & Washington Blvd            31.0     Wells St & Walton St   \n",
       "2  Sheffield Ave & Kingsbury St            15.0  Dearborn St & Monroe St   \n",
       "\n",
       "   end_capacity  temperature  wind_speed        events  \n",
       "0          15.0         73.9        12.7  mostlycloudy  \n",
       "1          19.0         69.1         6.9  partlycloudy  \n",
       "2          23.0         73.0        16.1  mostlycloudy  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes = pd.read_csv('../data/bikes.csv')\n",
    "bikes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ex 1: Custom Binning (0-100, 101-1000, 1001+) ---\n",
      "tripduration\n",
      "Short (0-100)          242\n",
      "Medium (101-1000)    39669\n",
      "Long (1001+)         10178\n",
      "Name: count, dtype: int64\n",
      "\n",
      "--- Ex 2: Equal Width Binning (Does it make sense?) ---\n",
      "tripduration\n",
      "(-26.128, 17285.6]    50060\n",
      "(17285.6, 34511.2]       11\n",
      "(34511.2, 51736.8]        9\n",
      "(51736.8, 68962.4]        3\n",
      "(68962.4, 86188.0]        6\n",
      "Name: count, dtype: int64\n",
      "Architect's Verdict: NO. The data is heavily right-skewed. Bin 1 contains 99% of data.\n",
      "\n",
      "--- Ex 3: Equal Frequency Binning (Quantiles) ---\n",
      "tripduration\n",
      "(59.999, 317.0]      10043\n",
      "(317.0, 480.0]       10011\n",
      "(480.0, 682.0]       10024\n",
      "(682.0, 1007.0]       9997\n",
      "(1007.0, 86188.0]    10014\n",
      "Name: count, dtype: int64\n",
      "Architect's Verdict: YES. This creates balanced groups for comparison.\n",
      "\n",
      "--- Ex 4: Duration vs Temperature Crosstab ---\n",
      "temperature   Coldest  Cold   Med   Hot  Hottest\n",
      "tripduration                                    \n",
      "Shortest         2712  2204  1931  1670     1526\n",
      "Short            2412  1947  2068  1927     1657\n",
      "Med              2151  2103  2067  1917     1786\n",
      "Long             1832  1940  2180  2101     1944\n",
      "Longest          1458  1754  2328  2331     2143\n",
      "\n",
      "--- Ex 5: Avg Duration by Gender & Temp Deciles ---\n",
      "temperature  (-9999.001, 37.0]  (37.0, 48.0]  (48.0, 55.9]\n",
      "gender                                                    \n",
      "Female              796.886049    670.031379    762.476715\n",
      "Male                586.972940    647.648968    622.234574\n",
      "\n",
      "--- Ex 6: Semantic Weather Buckets (with NaNs) ---\n",
      "temperature\n",
      "Cold     6434\n",
      "Cool     8483\n",
      "Mild    14819\n",
      "Warm    18355\n",
      "Hot      1998\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nealv\\AppData\\Local\\Temp\\ipykernel_42244\\685940685.py:82: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  return df.pivot_table(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# SETUP: Load and Validate Data\n",
    "# ------------------------------------------------------------------------------\n",
    "bikes = pd.read_csv('../data/bikes.csv')\n",
    "\n",
    "# Architect's Note:\n",
    "# Binning transforms continuous numerical data into discrete categories.\n",
    "# This is crucial for handling outliers, non-linear relationships, and simplifying reporting.\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# EXERCISE 1: Custom Binning (0-100, 101-1000, 1001+)\n",
    "# ------------------------------------------------------------------------------\n",
    "def classify_trip_duration(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Categorizes trips into custom logical buckets.\n",
    "    Explanation:\n",
    "    - pd.cut() allows defining specific boundaries.\n",
    "    - We use -1 instead of 0 for the lower bound to strictly include 0 if present.\n",
    "    - Labels make the result human-readable immediately.\n",
    "    \"\"\"\n",
    "    return pd.cut(\n",
    "        df['tripduration'],\n",
    "        bins=[-1, 100, 1000, np.inf],\n",
    "        labels=['Short (0-100)', 'Medium (101-1000)', 'Long (1001+)']\n",
    "    ).value_counts().sort_index()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# EXERCISE 2: Equal-Width Binning\n",
    "# ------------------------------------------------------------------------------\n",
    "def equal_width_analysis(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cuts data into 5 bins of equal 'range' (width).\n",
    "    Explanation:\n",
    "    - bins=5 calculates (max - min) / 5.\n",
    "    - ISSUE: In distributions with outliers (power law), this is often useless.\n",
    "      Most data clusters in the first bin, while empty bins stretch to the outliers.\n",
    "    \"\"\"\n",
    "    return pd.cut(df['tripduration'], bins=5).value_counts().sort_index()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# EXERCISE 3: Equal-Frequency (Quantile) Binning\n",
    "# ------------------------------------------------------------------------------\n",
    "def equal_freq_analysis(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cuts data into 5 bins with equal 'counts' (quantiles).\n",
    "    Explanation:\n",
    "    - pd.qcut() splits data so each bin has ~20% of the rows.\n",
    "    - RESULT: Much more useful for skewed data (like trip durations) as it \n",
    "      reveals the distribution relative to the population density.\n",
    "    \"\"\"\n",
    "    return pd.qcut(df['tripduration'], q=5).value_counts().sort_index()\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# EXERCISE 4: Bivariate Quantile Analysis (Crosstab)\n",
    "# ------------------------------------------------------------------------------\n",
    "def duration_temp_crosstab(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyzes the relationship between Temperature and Trip Duration.\n",
    "    Explanation:\n",
    "    - We discretize BOTH variables into quantiles (low, med, high, etc.).\n",
    "    - pd.crosstab() creates a frequency matrix (Heatmap data).\n",
    "    - Pattern Search: Do long trips happen more in mild weather?\n",
    "    \"\"\"\n",
    "    return pd.crosstab(\n",
    "        index=pd.qcut(df['tripduration'], q=5, labels=['Shortest', 'Short', 'Med', 'Long', 'Longest']),\n",
    "        columns=pd.qcut(df['temperature'], q=5, labels=['Coldest', 'Cold', 'Med', 'Hot', 'Hottest'])\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# EXERCISE 5: Pivot Table with Binned Columns\n",
    "# ------------------------------------------------------------------------------\n",
    "def pivot_duration_gender_temp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates Average Trip Duration by Gender across Temperature Deciles.\n",
    "    Explanation:\n",
    "    - We bin temperature into 10 buckets (deciles) inside the pivot_table call.\n",
    "    - This creates a detailed profile of how behavior changes with weather.\n",
    "    \"\"\"\n",
    "    return df.pivot_table(\n",
    "        index='gender',\n",
    "        columns=pd.qcut(df['temperature'], q=10),\n",
    "        values='tripduration',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# EXERCISE 6: Handling Data Quality & Contextual Binning\n",
    "# ------------------------------------------------------------------------------\n",
    "def clean_and_bin_temperature(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    1. Identifies and removes the anomaly (9999 or similar).\n",
    "    2. Bins valid data into semantic categories (Cold -> Hot).\n",
    "    3. Counts occurrences, explicitly tracking Missing Values (NaN).\n",
    "    \"\"\"\n",
    "    # 1. Clean: Replace impossible temps (e.g., > 150F) with NaN\n",
    "    # Architect's Note: Using .where() for vectorized replacement\n",
    "    clean_temp = df['temperature'].where(df['temperature'] < 150, np.nan)\n",
    "    \n",
    "    # 2. Bin: Define semantic boundaries (Fahrenheit assumptions)\n",
    "    # Cold: <40, Cool: 40-55, Mild: 55-70, Warm: 70-85, Hot: >85\n",
    "    return pd.cut(\n",
    "        clean_temp,\n",
    "        bins=[-np.inf, 40, 55, 70, 85, np.inf],\n",
    "        labels=['Cold', 'Cool', 'Mild', 'Warm', 'Hot']\n",
    "    ).value_counts(dropna=False).sort_index() # dropna=False keeps NaNs visible\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# EXECUTION & ANALYSIS\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"--- Ex 1: Custom Binning (0-100, 101-1000, 1001+) ---\")\n",
    "print(classify_trip_duration(bikes))\n",
    "\n",
    "print(\"\\n--- Ex 2: Equal Width Binning (Does it make sense?) ---\")\n",
    "print(equal_width_analysis(bikes))\n",
    "print(\"Architect's Verdict: NO. The data is heavily right-skewed. Bin 1 contains 99% of data.\")\n",
    "\n",
    "print(\"\\n--- Ex 3: Equal Frequency Binning (Quantiles) ---\")\n",
    "print(equal_freq_analysis(bikes))\n",
    "print(\"Architect's Verdict: YES. This creates balanced groups for comparison.\")\n",
    "\n",
    "print(\"\\n--- Ex 4: Duration vs Temperature Crosstab ---\")\n",
    "print(duration_temp_crosstab(bikes))\n",
    "\n",
    "print(\"\\n--- Ex 5: Avg Duration by Gender & Temp Deciles ---\")\n",
    "print(pivot_duration_gender_temp(bikes).iloc[:, :3]) # Showing first 3 deciles for brevity\n",
    "\n",
    "print(\"\\n--- Ex 6: Semantic Weather Buckets (with NaNs) ---\")\n",
    "print(clean_and_bin_temperature(bikes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Find the number of rides between trip durations of 0 to 100, 101 to 1000, and 1001 and above.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration\n",
       "Short (0-100)          242\n",
       "Medium (101-1000)    39669\n",
       "Long (1001+)         10178\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify_trip_duration(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Cut the trip duration into five bins where the width of each bin is the same size. Count the occurrence of each bin. Sort the resulting Series by the index. Does it make sense to use the type of binning?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration\n",
       "(-26.128, 17285.6]    50060\n",
       "(17285.6, 34511.2]       11\n",
       "(34511.2, 51736.8]        9\n",
       "(51736.8, 68962.4]        3\n",
       "(68962.4, 86188.0]        6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_width_analysis(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Cut the trip duration into five bins where the number of observations in each bin is the approximately the same. Count the occurrence of each bin. Sort the resulting Series by the index. Does it make sense to use the type of binning?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tripduration\n",
       "(59.999, 317.0]      10043\n",
       "(317.0, 480.0]       10011\n",
       "(480.0, 682.0]       10024\n",
       "(682.0, 1007.0]       9997\n",
       "(1007.0, 86188.0]    10014\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_freq_analysis(bikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Quantile cut trip duration and temperature into five equal-sized bins and count the occurrences using `pd.crosstab`. Do you notice any patterns?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>temperature</th>\n",
       "      <th>Coldest</th>\n",
       "      <th>Cold</th>\n",
       "      <th>Med</th>\n",
       "      <th>Hot</th>\n",
       "      <th>Hottest</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tripduration</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Shortest</th>\n",
       "      <td>2712</td>\n",
       "      <td>2204</td>\n",
       "      <td>1931</td>\n",
       "      <td>1670</td>\n",
       "      <td>1526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Short</th>\n",
       "      <td>2412</td>\n",
       "      <td>1947</td>\n",
       "      <td>2068</td>\n",
       "      <td>1927</td>\n",
       "      <td>1657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Med</th>\n",
       "      <td>2151</td>\n",
       "      <td>2103</td>\n",
       "      <td>2067</td>\n",
       "      <td>1917</td>\n",
       "      <td>1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Long</th>\n",
       "      <td>1832</td>\n",
       "      <td>1940</td>\n",
       "      <td>2180</td>\n",
       "      <td>2101</td>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Longest</th>\n",
       "      <td>1458</td>\n",
       "      <td>1754</td>\n",
       "      <td>2328</td>\n",
       "      <td>2331</td>\n",
       "      <td>2143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "temperature   Coldest  Cold   Med   Hot  Hottest\n",
       "tripduration                                    \n",
       "Shortest         2712  2204  1931  1670     1526\n",
       "Short            2412  1947  2068  1927     1657\n",
       "Med              2151  2103  2067  1917     1786\n",
       "Long             1832  1940  2180  2101     1944\n",
       "Longest          1458  1754  2328  2331     2143"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_temp_crosstab(bikes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Create a pivot table containing the average trip duration by gender and temperature quantile cut into 10 equal-sized bins.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nealv\\AppData\\Local\\Temp\\ipykernel_42244\\685940685.py:82: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  return df.pivot_table(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>temperature</th>\n",
       "      <th>(-9999.001, 37.0]</th>\n",
       "      <th>(37.0, 48.0]</th>\n",
       "      <th>(48.0, 55.9]</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>796.886049</td>\n",
       "      <td>670.031379</td>\n",
       "      <td>762.476715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>586.972940</td>\n",
       "      <td>647.648968</td>\n",
       "      <td>622.234574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "temperature  (-9999.001, 37.0]  (37.0, 48.0]  (48.0, 55.9]\n",
       "gender                                                    \n",
       "Female              796.886049    670.031379    762.476715\n",
       "Male                586.972940    647.648968    622.234574"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pivot_duration_gender_temp(bikes).iloc[:, :3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">The temperature column has a single obviously wrong value. Replace this value with the numpy nan object and then cut the resulting Series into five bins, labeling them 'cold', 'cool', 'mild', 'warm', 'hot'. Choose the boundaries of the bins that make sense for these labels. Then count the occurence of each label and include the missing values.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temperature\n",
       "Cold     6434\n",
       "Cool     8483\n",
       "Mild    14819\n",
       "Warm    18355\n",
       "Hot      1998\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "clean_and_bin_temperature(bikes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

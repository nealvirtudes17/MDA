{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Aggregation\n",
    "\n",
    "Pandas groupby objects come with many built-in aggregation functions. These are all available as strings within the `agg` method. There are, of course, many other aggregations that are not directly available and only possible by defining a custom aggregation function. These customized functions must return a single value. We begin by reading in the City of Houston dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>title</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Police</td>\n",
       "      <td>POLICE SERGEANT</td>\n",
       "      <td>2001-12-03</td>\n",
       "      <td>87545.38</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>ASSISTANT CITY ATTORNEY II</td>\n",
       "      <td>2010-11-15</td>\n",
       "      <td>82182.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hispanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Houston Public Works</td>\n",
       "      <td>SENIOR SLUDGE PROCESSOR</td>\n",
       "      <td>2006-01-09</td>\n",
       "      <td>49275.00</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dept                       title   hire_date    salary  \\\n",
       "0                Police             POLICE SERGEANT  2001-12-03  87545.38   \n",
       "1                 Other  ASSISTANT CITY ATTORNEY II  2010-11-15  82182.00   \n",
       "2  Houston Public Works     SENIOR SLUDGE PROCESSOR  2006-01-09  49275.00   \n",
       "\n",
       "    sex      race  \n",
       "0  Male     White  \n",
       "1  Male  Hispanic  \n",
       "2  Male     Black  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "emp = pd.read_csv('../data/employee.csv')\n",
    "emp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing your own custom aggregation function\n",
    "\n",
    "Suppose you would like to know the difference between the max and min value of a column for each group. Pandas does not have an aggregation function built to do this, so you will have to define this one yourself. \n",
    "\n",
    "Each customized aggregation function is defined as a regular Python function with the `def` keyword. Each function is **implicitly** passed the aggregating column of the group as a **Series**. This means that all Series methods will work on the passed argument. The `min_max` function below takes one argument, `s`, which is a Series object. It returns the difference between the max and min values of that Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max(s):\n",
    "    return s.max() - s.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a customized aggregation function\n",
    "\n",
    "Customized aggregation functions are used similarly as their built-in counterparts. Use the function variable name instead of a string with the`agg` method. The following finds the difference between the maximum and minimum salaries within each department. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_max_salary_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>326373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>161621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System</th>\n",
       "      <td>248875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Public Works</th>\n",
       "      <td>246795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>160088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>250040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>125040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>253085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>167960.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         min_max_salary_diff\n",
       "dept                                        \n",
       "Fire                                326373.0\n",
       "Health & Human Services             161621.0\n",
       "Houston Airport System              248875.0\n",
       "Houston Public Works                246795.0\n",
       "Library                             160088.0\n",
       "Other                               250040.0\n",
       "Parks & Recreation                  125040.0\n",
       "Police                              253085.0\n",
       "Solid Waste Management              167960.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp.groupby('dept').agg(min_max_salary_diff=('salary', min_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit passing of aggregation Series\n",
    "\n",
    "The above `agg` method passed the `salary` column as a Series to our customized aggregation function, `min_max`, for each group. The parameter `s` takes on this Series. We say this is implicit, because we don't actually see the function executed. Here is an **explicit** call to `min_max` function where we pass it the entire salary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(332872.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_max(emp['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom aggregation function is not passed the salary column of the entire DataFrame as done above, but just the salary column for the current group. Let's manually recreate the grouping that pandas did by first getting the unique department values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fire', 'Health & Human Services', 'Houston Airport System',\n",
       "       'Houston Public Works', 'Library', 'Other', 'Parks & Recreation',\n",
       "       'Police', 'Solid Waste Management'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_depts = emp['dept'].drop_duplicates().sort_values()\n",
    "unique_depts.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can loop through these departments and filter for just the salary of that department and pass that Series into the `min_max` function. The the results are then printed to the screen matching the above work done by pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fire                           326373.0\n",
      "Health & Human Services        161621.0\n",
      "Houston Airport System         248875.0\n",
      "Houston Public Works           246795.0\n",
      "Library                        160088.0\n",
      "Other                          250040.0\n",
      "Parks & Recreation             125040.0\n",
      "Police                         253085.0\n",
      "Solid Waste Management         167960.0\n"
     ]
    }
   ],
   "source": [
    "for dept in unique_depts:\n",
    "    salary_group = emp.query('dept == @dept')['salary']\n",
    "    min_max_diff = min_max(salary_group)\n",
    "    print(f'{dept:30} {min_max_diff}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an anonymous function\n",
    "\n",
    "For custom aggregation functions that have just a single line of code with little logic, an anonymous function can be used. If the aggregation will be reused or there is complex logic, then define a normal function. Here, we use an anonymous function to recreate the result of `min_max`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_max_salary_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>326373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>161621.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System</th>\n",
       "      <td>248875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Public Works</th>\n",
       "      <td>246795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>160088.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>250040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>125040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>253085.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>167960.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         min_max_salary_diff\n",
       "dept                                        \n",
       "Fire                                326373.0\n",
       "Health & Human Services             161621.0\n",
       "Houston Airport System              248875.0\n",
       "Houston Public Works                246795.0\n",
       "Library                             160088.0\n",
       "Other                               250040.0\n",
       "Parks & Recreation                  125040.0\n",
       "Police                              253085.0\n",
       "Solid Waste Management              167960.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emp.groupby('dept')\n",
    "    .agg(min_max_salary_diff=('salary', lambda s: s.max() - s.min())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Custom aggregation functions must return a single value\n",
    "\n",
    "The custom aggregation function you define must return a single value or else an exception will be raised. Let's create a custom aggregation that adds 5 to each value. This will return a Series the same size as the group and not a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add5(s):\n",
    "    return s + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempting to use this custom aggregation results in an error informing us that we did not produce an aggregated value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must produce aggregated value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43memp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdept\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43msalary_plus_5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msalary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd5\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1432\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m   1431\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m-> 1432\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:190\u001b[0m, in \u001b[0;36mApply.agg\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(func):\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:423\u001b[0m, in \u001b[0;36mApply.agg_dict_like\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_dict_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m    416\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a dict-like argument.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_or_apply_dict_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1603\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_dict_like\u001b[1;34m(self, op_name)\u001b[0m\n\u001b[0;32m   1598\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: engine_kwargs})\n\u001b[0;32m   1600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[0;32m   1601\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1602\u001b[0m ):\n\u001b[1;32m-> 1603\u001b[0m     result_index, result_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_dict_like\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   1605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1606\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_dict_like(selected_obj, result_index, result_data)\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:496\u001b[0m, in \u001b[0;36mApply.compute_dict_like\u001b[1;34m(self, op_name, selected_obj, selection, kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m key_data\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    500\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:497\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    493\u001b[0m         results \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m key_data\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;66;03m# key used for column selection and output\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 497\u001b[0m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gotitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, how \u001b[38;5;129;01min\u001b[39;00m func\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(func\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keys, results\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:257\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m    256\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m--> 257\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_multiple_funcs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:362\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[1;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[0;32m    361\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[1;32m--> 362\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:294\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_python_agg_general(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_agg_general\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;66;03m# KeyError raised in test_groupby.test_basic is bc the func does\u001b[39;00m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;66;03m#  a dictionary lookup on group.name, but group name is not\u001b[39;00m\n\u001b[0;32m    298\u001b[0m     \u001b[38;5;66;03m#  pinned in _python_agg_general, only in _aggregate_named\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_named(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:327\u001b[0m, in \u001b[0;36mSeriesGroupBy._python_agg_general\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: func(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    326\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj_with_exclusions\n\u001b[1;32m--> 327\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grouper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m res \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_constructor(result, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_aggregated_output(res)\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39m_values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;66;03m# we can preserve a little bit more aggressively with EA dtype\u001b[39;00m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m#  because maybe_cast_pointwise_result will do a try/except\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m#  with _from_sequence.  NB we are assuming here that _from_sequence\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;66;03m#  is sufficiently strict that it casts appropriately.\u001b[39;00m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_aggregate_series_pure_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preserve_dtype:\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:890\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    886\u001b[0m res \u001b[38;5;241m=\u001b[39m extract_result(res)\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m initialized:\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;66;03m# We only do this validation on the first iteration\u001b[39;00m\n\u001b[1;32m--> 890\u001b[0m     \u001b[43mcheck_result_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m     initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    893\u001b[0m result[i] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\nealv\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:88\u001b[0m, in \u001b[0;36mcheck_result_array\u001b[1;34m(obj, dtype)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;66;03m# If it is object dtype, the function can be a reduction/aggregation\u001b[39;00m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;66;03m#  and still return an ndarray e.g. test_agg_over_numpy_arrays\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust produce aggregated value\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Must produce aggregated value"
     ]
    }
   ],
   "source": [
    "emp.groupby('dept').agg(salary_plus_5=('salary', add5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine custom and built-in aggregation functions\n",
    "\n",
    "The custom aggregation function can be used in conjunction with any number of other built-in aggregation functions that we have previously seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_0c206\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank\" >&nbsp;</th>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0c206_level0_col0\" class=\"col_heading level0 col0\" >min_salary</th>\n",
       "      <th id=\"T_0c206_level0_col1\" class=\"col_heading level0 col1\" >max_salary</th>\n",
       "      <th id=\"T_0c206_level0_col2\" class=\"col_heading level0 col2\" >min_max_salary_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >dept</th>\n",
       "      <th class=\"index_name level1\" >sex</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level0_row0\" class=\"row_heading level0 row0\" rowspan=\"2\">Fire</th>\n",
       "      <th id=\"T_0c206_level1_row0\" class=\"row_heading level1 row0\" >Female</th>\n",
       "      <td id=\"T_0c206_row0_col0\" class=\"data row0 col0\" >16,000</td>\n",
       "      <td id=\"T_0c206_row0_col1\" class=\"data row0 col1\" >343,000</td>\n",
       "      <td id=\"T_0c206_row0_col2\" class=\"data row0 col2\" >326,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level1_row1\" class=\"row_heading level1 row1\" >Male</th>\n",
       "      <td id=\"T_0c206_row1_col0\" class=\"data row1 col0\" >17,000</td>\n",
       "      <td id=\"T_0c206_row1_col1\" class=\"data row1 col1\" >343,000</td>\n",
       "      <td id=\"T_0c206_row1_col2\" class=\"data row1 col2\" >326,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level0_row2\" class=\"row_heading level0 row2\" rowspan=\"2\">Health & Human Services</th>\n",
       "      <th id=\"T_0c206_level1_row2\" class=\"row_heading level1 row2\" >Female</th>\n",
       "      <td id=\"T_0c206_row2_col0\" class=\"data row2 col0\" >25,000</td>\n",
       "      <td id=\"T_0c206_row2_col1\" class=\"data row2 col1\" >187,000</td>\n",
       "      <td id=\"T_0c206_row2_col2\" class=\"data row2 col2\" >162,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level1_row3\" class=\"row_heading level1 row3\" >Male</th>\n",
       "      <td id=\"T_0c206_row3_col0\" class=\"data row3 col0\" >25,000</td>\n",
       "      <td id=\"T_0c206_row3_col1\" class=\"data row3 col1\" >187,000</td>\n",
       "      <td id=\"T_0c206_row3_col2\" class=\"data row3 col2\" >162,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level0_row4\" class=\"row_heading level0 row4\" rowspan=\"2\">Houston Airport System</th>\n",
       "      <th id=\"T_0c206_level1_row4\" class=\"row_heading level1 row4\" >Female</th>\n",
       "      <td id=\"T_0c206_row4_col0\" class=\"data row4 col0\" >26,000</td>\n",
       "      <td id=\"T_0c206_row4_col1\" class=\"data row4 col1\" >180,000</td>\n",
       "      <td id=\"T_0c206_row4_col2\" class=\"data row4 col2\" >154,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level1_row5\" class=\"row_heading level1 row5\" >Male</th>\n",
       "      <td id=\"T_0c206_row5_col0\" class=\"data row5 col0\" >26,000</td>\n",
       "      <td id=\"T_0c206_row5_col1\" class=\"data row5 col1\" >275,000</td>\n",
       "      <td id=\"T_0c206_row5_col2\" class=\"data row5 col2\" >249,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level0_row6\" class=\"row_heading level0 row6\" rowspan=\"2\">Houston Public Works</th>\n",
       "      <th id=\"T_0c206_level1_row6\" class=\"row_heading level1 row6\" >Female</th>\n",
       "      <td id=\"T_0c206_row6_col0\" class=\"data row6 col0\" >29,000</td>\n",
       "      <td id=\"T_0c206_row6_col1\" class=\"data row6 col1\" >275,000</td>\n",
       "      <td id=\"T_0c206_row6_col2\" class=\"data row6 col2\" >246,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level1_row7\" class=\"row_heading level1 row7\" >Male</th>\n",
       "      <td id=\"T_0c206_row7_col0\" class=\"data row7 col0\" >28,000</td>\n",
       "      <td id=\"T_0c206_row7_col1\" class=\"data row7 col1\" >216,000</td>\n",
       "      <td id=\"T_0c206_row7_col2\" class=\"data row7 col2\" >188,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level0_row8\" class=\"row_heading level0 row8\" rowspan=\"2\">Library</th>\n",
       "      <th id=\"T_0c206_level1_row8\" class=\"row_heading level1 row8\" >Female</th>\n",
       "      <td id=\"T_0c206_row8_col0\" class=\"data row8 col0\" >10,000</td>\n",
       "      <td id=\"T_0c206_row8_col1\" class=\"data row8 col1\" >170,000</td>\n",
       "      <td id=\"T_0c206_row8_col2\" class=\"data row8 col2\" >160,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0c206_level1_row9\" class=\"row_heading level1 row9\" >Male</th>\n",
       "      <td id=\"T_0c206_row9_col0\" class=\"data row9 col0\" >11,000</td>\n",
       "      <td id=\"T_0c206_row9_col1\" class=\"data row9 col1\" >115,000</td>\n",
       "      <td id=\"T_0c206_row9_col2\" class=\"data row9 col2\" >105,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fbbf5b0d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emp.groupby(['dept', 'sex'])\n",
    "    .agg(min_salary=('salary', 'min'),\n",
    "         max_salary=('salary', 'max'),\n",
    "         min_max_salary_diff=('salary', min_max))\n",
    "    .head(10)\n",
    "    .round(-3)\n",
    "    .style.format('{:,.0f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the mean salary for the five highest paid employees per department\n",
    "\n",
    "In this section, we will find the mean salary of the five highest paid employees per department. This again requires a custom aggregation function. The same Series of salaries will be implicitly passed to it. We use the `nlargest` method to select the top five salaries and then take the mean of them to return a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_mean(s: pd.Series) -> float:\n",
    "    return s.nlargest(5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this function to generate the desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_07546\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_07546_level0_col0\" class=\"col_heading level0 col0\" >top5_average_salary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >dept</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row0\" class=\"row_heading level0 row0\" >Fire</th>\n",
       "      <td id=\"T_07546_row0_col0\" class=\"data row0 col0\" >343,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row1\" class=\"row_heading level0 row1\" >Health & Human Services</th>\n",
       "      <td id=\"T_07546_row1_col0\" class=\"data row1 col0\" >182,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row2\" class=\"row_heading level0 row2\" >Houston Airport System</th>\n",
       "      <td id=\"T_07546_row2_col0\" class=\"data row2 col0\" >212,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row3\" class=\"row_heading level0 row3\" >Houston Public Works</th>\n",
       "      <td id=\"T_07546_row3_col0\" class=\"data row3 col0\" >206,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row4\" class=\"row_heading level0 row4\" >Library</th>\n",
       "      <td id=\"T_07546_row4_col0\" class=\"data row4 col0\" >132,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row5\" class=\"row_heading level0 row5\" >Other</th>\n",
       "      <td id=\"T_07546_row5_col0\" class=\"data row5 col0\" >225,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row6\" class=\"row_heading level0 row6\" >Parks & Recreation</th>\n",
       "      <td id=\"T_07546_row6_col0\" class=\"data row6 col0\" >129,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row7\" class=\"row_heading level0 row7\" >Police</th>\n",
       "      <td id=\"T_07546_row7_col0\" class=\"data row7 col0\" >211,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_07546_level0_row8\" class=\"row_heading level0 row8\" >Solid Waste Management</th>\n",
       "      <td id=\"T_07546_row8_col0\" class=\"data row8 col0\" >148,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1fbbf5bbc50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emp.groupby('dept')\n",
    "    .agg(top5_average_salary=('salary', top5_mean))\n",
    "    .round(-3)\n",
    "    .style.format('{:,.0f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What percent of total salary do these five employees represent?\n",
    "\n",
    "Let's take our question a step further and determine the percentage of the total salary from each department that these five employees represent. Instead of finding the mean, we take the sum of the top five salaries and divide it by the sum of all salaries for that department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_percent(s):\n",
    "    return s.nlargest(5).sum() / s.sum() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we pass our function to the `agg` method to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top5_average_salary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System</th>\n",
       "      <td>1.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Public Works</th>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>2.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         top5_average_salary\n",
       "dept                                        \n",
       "Fire                                    0.65\n",
       "Health & Human Services                 1.22\n",
       "Houston Airport System                  1.58\n",
       "Houston Public Works                    0.48\n",
       "Library                                 2.78\n",
       "Other                                   0.54\n",
       "Parks & Recreation                      1.51\n",
       "Police                                  0.24\n",
       "Solid Waste Management                  3.30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emp.groupby('dept')\n",
    "    .agg(top5_average_salary=('salary', top5_percent))\n",
    "    .round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results tell us that the top five highest paid employees of the fire department represent 0.65% of the total combined fire department salary. Let's verify this by calculating it without using `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6465830603130651)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_sal_sorted = (emp.query('dept == \"Fire\"')['salary']\n",
    "                      .sort_values(ascending=False))\n",
    "fire_sal_sorted.iloc[:5].sum() / fire_sal_sorted.sum() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results would be more meaningful if we also calculated the percentage of the number of employees that these five represent. For instance, if there are 200 fire department employees, then five would represent 2.5% (5 / 200). Another custom aggregation function is defined below. Notice that the `count` method is used as several employees are missing salaries. If there are less than five employees in the group, 100% will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count5_percent(s):\n",
    "    return min(5 / s.count(), 1) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use both custom aggregation functions along with the built-in `count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top5_average_salary</th>\n",
       "      <th>count5_percent</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.11</td>\n",
       "      <td>4376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>1.22</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System</th>\n",
       "      <td>1.58</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Public Works</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.12</td>\n",
       "      <td>4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>2.78</td>\n",
       "      <td>0.89</td>\n",
       "      <td>563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>1.51</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>0.24</td>\n",
       "      <td>0.08</td>\n",
       "      <td>6627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>3.30</td>\n",
       "      <td>0.98</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         top5_average_salary  count5_percent  count\n",
       "dept                                                               \n",
       "Fire                                    0.65            0.11   4376\n",
       "Health & Human Services                 1.22            0.37   1353\n",
       "Houston Airport System                  1.58            0.41   1216\n",
       "Houston Public Works                    0.48            0.12   4190\n",
       "Library                                 2.78            0.89    563\n",
       "Other                                   0.54            0.15   3373\n",
       "Parks & Recreation                      1.51            0.43   1152\n",
       "Police                                  0.24            0.08   6627\n",
       "Solid Waste Management                  3.30            0.98    512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emp.groupby('dept')\n",
    "    .agg(top5_average_salary=('salary', top5_percent),\n",
    "         count5_percent=('salary', count5_percent),\n",
    "         count=('salary', 'count'))\n",
    "    .round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us more meaning behind the results. The five fire department employees account for 0.11% of all employees, but 0.65% of the total salary. Since not all employees receive the same salary, we expect the top five to have a disproportional percentage of the total salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a custom aggregation function in a pivot table\n",
    "\n",
    "As we learned, pivot tables are nearly identical to groupby aggregations. pandas allows you to set the `aggfunc` of the `pivot_table` method to a custom aggregation function. It will implicitly pass the Series of the `values` column to the aggregation function. Here we call the `top5_percent` on the salary column for each unique combination of department and sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sex</th>\n",
       "      <th>Female</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>10.13</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>1.64</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System</th>\n",
       "      <td>3.54</td>\n",
       "      <td>2.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Public Works</th>\n",
       "      <td>1.47</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>3.94</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0.86</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>3.98</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>9.27</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sex                      Female  Male\n",
       "dept                                 \n",
       "Fire                      10.13  0.69\n",
       "Health & Human Services    1.64  3.82\n",
       "Houston Airport System     3.54  2.39\n",
       "Houston Public Works       1.47  0.61\n",
       "Library                    3.94  7.46\n",
       "Other                      0.86  1.15\n",
       "Parks & Recreation         3.98  2.10\n",
       "Police                     0.92  0.30\n",
       "Solid Waste Management     9.27  4.33"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp.pivot_table(index='dept', columns='sex', \n",
    "                values='salary', aggfunc=top5_percent).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Percentage of employees by department with salaries greater than 100,000\n",
    "\n",
    "In this section, we'll find the percentage of employees by each department with salaries greater that 100,000 using a custom aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_gt_100k(s):\n",
    "    return (s > 100_000).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this custom function just like the others in this chapter to get our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_greater_100k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System</th>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Public Works</th>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>10.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         percent_greater_100k\n",
       "dept                                         \n",
       "Fire                                     0.87\n",
       "Health & Human Services                  5.76\n",
       "Houston Airport System                   8.06\n",
       "Houston Public Works                     4.01\n",
       "Library                                  1.60\n",
       "Other                                   10.44\n",
       "Parks & Recreation                       0.78\n",
       "Police                                   1.25\n",
       "Solid Waste Management                   2.34"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emp.groupby('dept')\n",
    "    .agg(percent_greater_100k=('salary', perc_gt_100k))\n",
    "    .round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not accounting for missing values\n",
    "\n",
    "Some employees do not have salaries and when we make the comparison `s > 100_000`, those missing values will evaluate as `False`. Let's find the number of employees per department that have missing values with an anonymous custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_missing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Public Works</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         num_missing\n",
       "dept                                \n",
       "Fire                               0\n",
       "Health & Human Services            0\n",
       "Houston Airport System             0\n",
       "Houston Public Works               0\n",
       "Library                            0\n",
       "Other                              0\n",
       "Parks & Recreation                 0\n",
       "Police                           946\n",
       "Solid Waste Management             0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(emp.groupby('dept')\n",
    "    .agg(num_missing=('salary', lambda x: x.isna().sum()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to find the percentage of employees with known salary that have a salary greater than 100,000, then we'll have to either drop these missing values or use a denominator that is equivalent to the number of employees with known values. Below, we use the first option to drop all the values in the current group that are missing. Only the police department's returned statistic changes, as it was the only one that had missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>percent_greater_100k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dept</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fire</th>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health &amp; Human Services</th>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Airport System</th>\n",
       "      <td>8.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Houston Public Works</th>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Library</th>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>10.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parks &amp; Recreation</th>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Police</th>\n",
       "      <td>1.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Solid Waste Management</th>\n",
       "      <td>2.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         percent_greater_100k\n",
       "dept                                         \n",
       "Fire                                     0.87\n",
       "Health & Human Services                  5.76\n",
       "Houston Airport System                   8.06\n",
       "Houston Public Works                     4.01\n",
       "Library                                  1.60\n",
       "Other                                   10.44\n",
       "Parks & Recreation                       0.78\n",
       "Police                                   1.43\n",
       "Solid Waste Management                   2.34"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perc_gt_100k_real(s):\n",
    "    return (s.dropna() > 100_000).mean() * 100\n",
    "\n",
    "(emp.groupby('dept')\n",
    "    .agg(percent_greater_100k=('salary', perc_gt_100k_real))\n",
    "    .round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing a custom aggregation function\n",
    "\n",
    "Custom aggregation functions have potential to perform poorly. pandas optimizes its own built-in aggregations but cannot do the same for the ones you define. This section will show you how to optimize the performance of your custom aggregation function.\n",
    "\n",
    "### Create a larger DataFrame to test performance\n",
    "\n",
    "Our current DataFrame contains only 24,000 rows. Performance metrics matter more with larger datasets. To simulate a larger dataset, we'll use the `sample` method to select 100,000 random rows with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>title</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>2003-08-25</td>\n",
       "      <td>61271.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Police</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>51654.98</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Police</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>2007-08-13</td>\n",
       "      <td>68116.62</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dept                      title   hire_date    salary  \\\n",
       "0  Solid Waste Management  ADMINISTRATIVE SPECIALIST  2003-08-25  61271.00   \n",
       "1                  Police             POLICE OFFICER  2017-07-17  51654.98   \n",
       "2                  Police             POLICE OFFICER  2007-08-13  68116.62   \n",
       "\n",
       "      sex   race  \n",
       "0  Female  Black  \n",
       "1    Male  Asian  \n",
       "2    Male  Asian  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_large = emp.sample(100_000, replace=True, ignore_index=True)\n",
    "emp_large.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that we have a DataFrame with 100,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_large.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's measure the performance of one of custom aggregation functions, `perc_gt_100k_real`, with this larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 8.45 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = emp_large.groupby('dept').agg({'salary': perc_gt_100k_real})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the built-in mean aggregation function is timed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 5.81 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = emp_large.groupby('dept').agg({'salary': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my machine, the custom aggregation function had similar performance to the built-in `mean`. The number of groups can greatly impact the performance of an operation. Let's take a look at the number of unique values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dept            9\n",
       "title         689\n",
       "hire_date    3924\n",
       "salary       4057\n",
       "sex             2\n",
       "race            5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_large.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are substantially more unique titles in our dataset. Let's use this column as the grouping column instead of department to show a larger difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = emp_large.groupby('title').agg({'salary': perc_gt_100k_real})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 9.52 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = emp_large.groupby('title').agg({'salary':'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On my machine, grouping by title was more than 10 times slower, showcasing the vast differences in performance when grouping by columns with a large number of groups. Each group must be passed to the custom function, so the more groups, the worse the performance.\n",
    "\n",
    "### Convert grouping columns to categorical\n",
    "\n",
    "The first step to help making your custom aggregation (and any aggregation) faster is to convert the grouping column to categorical if it is an object column containing strings. Grouping columns tend to be strings so it is a change that you'll do often. Here, we create two new category columns for department and title and append them to the end of our DataFrame. When performing this on your own data, overwrite the original columns. We keep the original columns in this instance to show the difference in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept</th>\n",
       "      <th>title</th>\n",
       "      <th>hire_date</th>\n",
       "      <th>salary</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>dept_cat</th>\n",
       "      <th>title_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "      <td>2003-08-25</td>\n",
       "      <td>61271.00</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>ADMINISTRATIVE SPECIALIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Police</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>51654.98</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Police</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Police</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "      <td>2007-08-13</td>\n",
       "      <td>68116.62</td>\n",
       "      <td>Male</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Police</td>\n",
       "      <td>POLICE OFFICER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     dept                      title   hire_date    salary  \\\n",
       "0  Solid Waste Management  ADMINISTRATIVE SPECIALIST  2003-08-25  61271.00   \n",
       "1                  Police             POLICE OFFICER  2017-07-17  51654.98   \n",
       "2                  Police             POLICE OFFICER  2007-08-13  68116.62   \n",
       "\n",
       "      sex   race                dept_cat                  title_cat  \n",
       "0  Female  Black  Solid Waste Management  ADMINISTRATIVE SPECIALIST  \n",
       "1    Male  Asian                  Police             POLICE OFFICER  \n",
       "2    Male  Asian                  Police             POLICE OFFICER  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = emp_large[['dept', 'title']].astype('category')\n",
    "emp_large[['dept_cat', 'title_cat']] = cat_cols\n",
    "emp_large.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before testing our custom function, let's compare the performance difference of the built-in `mean` function between the two versions of the department column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 6.22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = emp_large.groupby('dept').agg({'salary': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.64 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = emp_large.groupby('dept_cat').agg({'salary': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping with the categorical column reduced the completion time in half on my machine. Executing this comparison using title as the grouping column results in a similar performance gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 7.33 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = emp_large.groupby('title').agg({'salary': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.01 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = emp_large.groupby('title_cat').agg({'salary': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete operations that are independent of the group outside of the custom function\n",
    "\n",
    "The next step to optimizing your custom function is to look for operations that are independent of the group. The `perc_gt_100k_real` function has two computations that are independent of the group. Dropping missing values is independent of the group. It doesn't matter which department or title it is. We can drop all missing values BEFORE the groupby instead of WITHIN the custom function. This allows us to use the original `perc_gt_100k` function instead. Let's time the new operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 91.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = (emp_large.groupby('title_cat')\n",
    "              .agg({'salary': perc_gt_100k_real}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 67.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = (emp_large.dropna(subset=['salary'])\n",
    "              .groupby('title_cat')\n",
    "              .agg({'salary': perc_gt_100k}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A substantial 1/3 gain in performance was recorded. Dropping missing values causes pandas to create an entire new DataFrame (or Series) in memory. Doing this operation independently for all titles takes more time than doing it once for the entire DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary comparison is independent of the group\n",
    "\n",
    "The comparison between salary and 100,000 is completed for every group, but this operation is also independent of the group. We can do the comparison before any grouping. Below, we create a new boolean column for salaries greater than 100,000 and use it as the aggregating function. Now, there's no need for a custom function at all, which results in a massive performance improvement of about 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 7.98 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emp_large['salary_greater'] = emp_large['salary'] > 100_000\n",
    "_ = (emp_large.dropna(subset=['salary'])\n",
    "              .groupby('title_cat')['salary_greater'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid `dropna`\n",
    "\n",
    "The `dropna` method is fairly expensive as it creates an entire new DataFrame in memory of just the rows that do not have a missing salary. We can avoid it by taking the sum of the `salary_greater` column of each group and dividing by the number of non-missing values (`count` method). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 5.79 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emp_large['salary_greater'] = emp_large['salary'] > 100_000\n",
    "df_temp = emp_large.groupby('title_cat').agg(ct_over_100k=('salary_greater', 'sum'),\n",
    "                                             total_ct=('salary', 'count'))\n",
    "_ = df_temp['ct_over_100k'] / df_temp['total_ct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use alternative syntax\n",
    "\n",
    "Notice that the previous step does not improve performance. In order to see the improvement, you'll have to use alternative groupby syntax where a single Series of data is returned. Below, we assign the result of just the `groupby` method (before any aggregation) to the variable `g`. This object stores the grouping and allows you to calculate different aggregations for different aggregating columns. This improves performance by over 98% from the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.03 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emp_large['salary_greater'] = emp_large['salary'] > 100_000\n",
    "g = emp_large.groupby('title_cat')\n",
    "_ = g['salary_greater'].sum() /  g['salary'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One last alternative with pandas-only data types\n",
    "\n",
    "One of the issues with the default pandas data types is that comparisons with missing values evaluate as `False`. With the new pandas-only data types that use `pd.NA` as missing values, they stay missing. Below, we convert the salary column to the new nullable float data type which becomes a nullable boolean after the comparison keeping the missing values. Series also have a groupby method and can be grouped by a column of data in a different DataFrame as long as it's the same length. The categorical title column is used below. Finally the mean of the booleans is calculated on each group, returning the percentage greater than 100,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 9.94 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "s = (emp_large['salary'].astype('Float64') > 100_000)\n",
    "_ = s.groupby(emp_large['title_cat']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of performance improvement for custom aggregation functions\n",
    "\n",
    "* Convert grouping columns to categorical\n",
    "* Complete operations that are independent of the group outside of the custom function \n",
    "* Use built-in aggregations if possible\n",
    "* Use alternative groupby syntax\n",
    "* Use multiple built-in groupby aggregations if necessary\n",
    "\n",
    "### Complexity vs Performance\n",
    "\n",
    "This is usually a topic of debate when deciding on which Pandas methods to use. I typically like to avoid custom aggregation functions at all cost as they can drastically reduce performance for larger datasets.\n",
    "\n",
    "Readability (low complexity) is very valuable when sharing your code or looking back at it at a later date. Custom aggregation functions might provide more readability in some situations, but more often than not this isn't a large enough benefit, so I rarely use them as the performance difference is much more significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the cell below to read in the flights dataset and then use it for the following exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>airline</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>LAS</td>\n",
       "      <td>IAH</td>\n",
       "      <td>100</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>PHX</td>\n",
       "      <td>515</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BOS</td>\n",
       "      <td>550</td>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date airline origin dest  dep_time  arr_time  cancelled  air_time  \\\n",
       "0 2018-01-01      UA    LAS  IAH       100       547          0     134.0   \n",
       "1 2018-01-01      WN    DEN  PHX       515       720          0      91.0   \n",
       "2 2018-01-01      B6    JFK  BOS       550       657          0      39.0   \n",
       "\n",
       "   distance  carrier_delay  weather_delay  nas_delay  security_delay  \\\n",
       "0    1222.0              0              0          0               0   \n",
       "1     602.0              0              0          0               0   \n",
       "2     187.0              0             83          8               0   \n",
       "\n",
       "   late_aircraft_delay  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "flights = pd.read_csv('../data/flights.csv', parse_dates=['date'])\n",
    "flights.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">What are the three airlines with the least number of flights?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline\n",
       "EV    171\n",
       "OH    257\n",
       "MQ    373\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "flights.groupby('airline').size().nsmallest(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">For each airline, find the 75th percentile of flight distance. Use a custom aggregation function.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perc75</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9E</th>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>1558.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <td>2402.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B6</th>\n",
       "      <td>2381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>1587.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>514.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F9</th>\n",
       "      <td>1476.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MQ</th>\n",
       "      <td>612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NK</th>\n",
       "      <td>1379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OO</th>\n",
       "      <td>912.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UA</th>\n",
       "      <td>1635.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VX</th>\n",
       "      <td>2475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WN</th>\n",
       "      <td>1024.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YV</th>\n",
       "      <td>1075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YX</th>\n",
       "      <td>912.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         perc75\n",
       "airline        \n",
       "9E        852.0\n",
       "AA       1558.0\n",
       "AS       2402.0\n",
       "B6       2381.0\n",
       "DL       1587.0\n",
       "EV        514.5\n",
       "F9       1476.0\n",
       "MQ        612.0\n",
       "NK       1379.0\n",
       "OH        500.0\n",
       "OO        912.0\n",
       "UA       1635.0\n",
       "VX       2475.0\n",
       "WN       1024.0\n",
       "YV       1075.0\n",
       "YX        912.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perc_75th(s):\n",
    "    return s.quantile(0.75)\n",
    "\n",
    "flights.groupby('airline').agg(perc75=('distance',perc_75th))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">For each airline, find out what percentage of its flights leave on a Tuesday. Use a custom aggregation function.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>airline</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>LAS</td>\n",
       "      <td>IAH</td>\n",
       "      <td>100</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>PHX</td>\n",
       "      <td>515</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BOS</td>\n",
       "      <td>550</td>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date airline origin dest  dep_time  arr_time  cancelled  air_time  \\\n",
       "0 2018-01-01      UA    LAS  IAH       100       547          0     134.0   \n",
       "1 2018-01-01      WN    DEN  PHX       515       720          0      91.0   \n",
       "2 2018-01-01      B6    JFK  BOS       550       657          0      39.0   \n",
       "\n",
       "   distance  carrier_delay  weather_delay  nas_delay  security_delay  \\\n",
       "0    1222.0              0              0          0               0   \n",
       "1     602.0              0              0          0               0   \n",
       "2     187.0              0             83          8               0   \n",
       "\n",
       "   late_aircraft_delay  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                   datetime64[ns]\n",
       "airline                        object\n",
       "origin                         object\n",
       "dest                           object\n",
       "dep_time                        int64\n",
       "arr_time                        int64\n",
       "cancelled                       int64\n",
       "air_time                      float64\n",
       "distance                      float64\n",
       "carrier_delay                   int64\n",
       "weather_delay                   int64\n",
       "nas_delay                       int64\n",
       "security_delay                  int64\n",
       "late_aircraft_delay             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuesday_flights(df):\n",
    "    is_tuesday ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Optimize exercise 3 without using a custom aggregation. What is the performance difference?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">The range of salaries per department was calculated using the `min_max` custom function from the beginning of this chapter. Use this same function to calculate the range of distance for each airline. Then calculate this range again without a custom function.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Which origin airport has the highest percentage of its flights cancelled?</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the college dataset\n",
    "\n",
    "Execute the following cell which reads in a few columns from the college dataset, sets the institution name as the index and converts 'stabbr' and 'relaffil' to categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['instnm', 'stabbr', 'relaffil', 'satvrmid', 'satmtmid', 'ugds']\n",
    "college = pd.read_csv('../data/college.csv', usecols=cols, \n",
    "                      index_col='instnm', dtype={'stabbr': 'category', \n",
    "                                                 'relaffil': 'category'})\n",
    "college.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">How many states have more schools with a higher 'satvrmid' than 'satmtmid'? Make sure to not count schools that have missing values for either one.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "<span style=\"color:green; font-size:16px\">Create a pivot table that shows the percentage of schools with less than 1,000 students in each state by religious affiliation. Also return the count of schools.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

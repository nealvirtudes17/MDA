{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13896ffd",
   "metadata": {},
   "source": [
    "MODULE 1: DATA STRUCTURE & NUMERIC HYGIENE\n",
    "Dataset: sf_employee_compensation.csv Context: We need to audit the city's payroll. The dataset is large, so structure and memory optimization are priorities before we calculate salary statistics.\n",
    "\n",
    "Topics: Intro methods, Structure methods, Numeric methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95f61fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Structure Audit ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   year                50000 non-null  int64   \n",
      " 1   organization_group  50000 non-null  category\n",
      " 2   job                 50000 non-null  category\n",
      " 3   salaries            50000 non-null  float64 \n",
      " 4   overtime            50000 non-null  float64 \n",
      " 5   other_salaries      50000 non-null  float64 \n",
      " 6   retirement          50000 non-null  float64 \n",
      " 7   health_and_dental   50000 non-null  float64 \n",
      " 8   other_benefits      50000 non-null  float64 \n",
      " 9   total_benefits      50000 non-null  float64 \n",
      " 10  total_compensation  50000 non-null  float64 \n",
      "dtypes: category(2), float64(8), int64(1)\n",
      "memory usage: 3.7 MB\n",
      "\n",
      "Shape: (50000, 11)\n",
      "\n",
      "--- Correlation: Salaries vs Total Benefits ---\n",
      "Pearson r: 0.9170\n",
      "\n",
      "--- Highest Compensated Role ---\n",
      "                    job  total_compensation\n",
      "42437  Police Officer 3           798820.18\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. INGESTION & ROBUST DATA PIPELINE\n",
    "# Architect's Note: The raw file lacks 'total_benefits' and 'total_compensation' columns.\n",
    "# We must engineer them explicitly in the pipeline to avoid KeyErrors.\n",
    "\n",
    "sf_payroll = (\n",
    "    pd.read_csv('../data/sf_employee_compensation.csv')\n",
    "    # CRITICAL STEP: Standardize headers to match code references (e.g., \"Health and Dental\" -> \"health_and_dental\")\n",
    "    .rename(columns=lambda c: c.strip().lower().replace(' ', '_'))\n",
    "    \n",
    "    # 2. FEATURE ENGINEERING (The \"Atomic\" Approach)\n",
    "    # Improvement: Use .sum(axis=1) instead of (+) to treat NaNs as 0 (Safe Math)\n",
    "    .assign(\n",
    "        total_benefits=lambda df_: df_[[\n",
    "            'retirement', \n",
    "            'health_and_dental', \n",
    "            'other_benefits'\n",
    "        ]].sum(axis=1, min_count=0)\n",
    "    )\n",
    "    # Chaining: Calculate Total Comp using the newly created 'total_benefits'\n",
    "    .assign(\n",
    "        total_compensation=lambda df_: df_[[\n",
    "            'salaries', \n",
    "            'overtime', \n",
    "            'other_salaries', \n",
    "            'total_benefits'\n",
    "        ]].sum(axis=1, min_count=0),\n",
    "        \n",
    "        # Optimize Types\n",
    "        organization_group=lambda df_: df_['organization_group'].astype('category'),\n",
    "        job=lambda df_: df_['job'].astype('category')\n",
    "    )\n",
    "    .set_index('year')\n",
    ")\n",
    "\n",
    "# 2. STRUCTURAL AUDIT\n",
    "print(\"--- Structure Audit ---\")\n",
    "sf_payroll.info(verbose=True, memory_usage='deep')\n",
    "print(f\"\\nShape: {sf_payroll.shape}\")\n",
    "\n",
    "# 3. ANALYSIS PIPELINE\n",
    "# Goal: Correlate salaries with benefits and identify top earners.\n",
    "\n",
    "numeric_analysis = (\n",
    "    sf_payroll\n",
    "    .select_dtypes(include=['number'])\n",
    "    # No 'year_type' found in source, so we skip dropping it to be safe, \n",
    "    # or strictly select known numeric columns to ensure purity.\n",
    ")\n",
    "\n",
    "# CORRELATION\n",
    "# Calculate Pearson correlation between base salaries and total benefits\n",
    "correlation_val = numeric_analysis['salaries'].corr(numeric_analysis['total_benefits'])\n",
    "\n",
    "# EXTREMES\n",
    "# Identify the job role with the single highest total compensation package\n",
    "highest_paid_idx = numeric_analysis['total_compensation'].idxmax()\n",
    "# Use .loc to retrieve the specific record based on the index (Year) and label logic\n",
    "# Since index is 'year' (non-unique), idxmax returns the label (e.g., 2013). \n",
    "# To get the exact row robustly without ambiguity if years duplicate, \n",
    "# we usually reset index or use iloc. However, strictly following the prompt's flow:\n",
    "# We will find the row with the max value directly to print details.\n",
    "highest_earner_row = sf_payroll.loc[sf_payroll['total_compensation'] == sf_payroll['total_compensation'].max()]\n",
    "\n",
    "print(f\"\\n--- Correlation: Salaries vs Total Benefits ---\")\n",
    "print(f\"Pearson r: {correlation_val:.4f}\")\n",
    "\n",
    "print(\"\\n--- Highest Compensated Role ---\")\n",
    "print(highest_earner_row[['job', 'total_compensation']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d5962",
   "metadata": {},
   "source": [
    "MODULE 2: THE QUALITY FILTER (MISSING VALUES & RANKING)\n",
    "Dataset: movie.csv Context: We are curating a list of \"Best Value\" movies. The raw data is messy. We need to handle missing financial data, remove duplicates, and rank movies by Return on Investment (ROI).\n",
    "\n",
    "Topics: Missing Value methods, Sorting, Ranking, Uniqueness, \"More\" methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb6aaccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Completeness (Post-Cleaning) ---\n",
      "gross     0\n",
      "budget    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "movies_raw = pd.read_csv('../data/movie.csv')\n",
    "\n",
    "# PRODUCTION PIPELINE: Cleaning & Ranking\n",
    "curated_catalog = (\n",
    "    movies_raw\n",
    "    # 1. HANDLING MISSING VALUES (The Strategy)\n",
    "    # Rule A: Drop rows where we can't calculate ROI (Budget or Gross is NaN)\n",
    "    .dropna(subset=['gross', 'budget'])\n",
    "    \n",
    "    # Rule B: Impute categorical gaps (Content Rating)\n",
    "    # Using .fillna() to categorize unknown movies\n",
    "    .assign(\n",
    "        content_rating=lambda df_: df_['content_rating'].fillna('Unrated')\n",
    "    )\n",
    "    \n",
    "    # 2. UNIQUENESS\n",
    "    # Rule: Remove duplicate movie titles, keeping the one with the highest gross\n",
    "    .sort_values('gross', ascending=False)\n",
    "    .drop_duplicates(subset=['title'], keep='first')\n",
    "    \n",
    "    # 3. FEATURE ENGINEERING (for Ranking)\n",
    "    .assign(roi=lambda df_: df_['gross'] / df_['budget'])\n",
    "    \n",
    "    # 4. SORTING & RANKING\n",
    "    # Sort by ROI descending\n",
    "    .sort_values('roi', ascending=False)\n",
    "    \n",
    "    # Rank: Assign a dense rank (1, 2, 3...) based on ROI\n",
    "    .assign(roi_rank=lambda df_: df_['roi'].rank(method='dense', ascending=False))\n",
    ")\n",
    "\n",
    "# 5. \"MORE\" DATAFRAME METHODS (Sampling & N-Extremes)\n",
    "# Business Requirement: Pick 5 random movies for the \"Staff Picks\" carousel\n",
    "staff_picks = curated_catalog.sample(n=5, random_state=42)\n",
    "\n",
    "# Business Requirement: Get the top 3 and bottom 3 movies by Budget (nsmallest/nlargest)\n",
    "budget_extremes = pd.concat([\n",
    "    curated_catalog.nlargest(3, 'budget'),\n",
    "    curated_catalog.nsmallest(3, 'budget')\n",
    "])\n",
    "\n",
    "print(\"--- Data Completeness (Post-Cleaning) ---\")\n",
    "# Verifying we dropped the critical missing data\n",
    "print(curated_catalog[['gross', 'budget']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "109294d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>color</th>\n",
       "      <th>content_rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>director_name</th>\n",
       "      <th>director_fb</th>\n",
       "      <th>actor1</th>\n",
       "      <th>actor1_fb</th>\n",
       "      <th>actor2</th>\n",
       "      <th>...</th>\n",
       "      <th>genres</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>num_voted_users</th>\n",
       "      <th>plot_keywords</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>budget</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>roi</th>\n",
       "      <th>roi_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>30 Minutes or Less</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>R</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Ruben Fleischer</td>\n",
       "      <td>181.0</td>\n",
       "      <td>Bianca Kajlich</td>\n",
       "      <td>731.0</td>\n",
       "      <td>Dilshad Vadsaria</td>\n",
       "      <td>...</td>\n",
       "      <td>Action|Comedy|Crime</td>\n",
       "      <td>220.0</td>\n",
       "      <td>77935</td>\n",
       "      <td>bank heist|bank robbery|heist gone wrong|pizza...</td>\n",
       "      <td>English</td>\n",
       "      <td>Germany</td>\n",
       "      <td>28000000.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.323354</td>\n",
       "      <td>1579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>Space Chimps</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>G</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Kirk De Micco</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Cheryl Hines</td>\n",
       "      <td>541.0</td>\n",
       "      <td>Kenan Thompson</td>\n",
       "      <td>...</td>\n",
       "      <td>Adventure|Animation|Comedy|Family|Sci-Fi</td>\n",
       "      <td>85.0</td>\n",
       "      <td>8860</td>\n",
       "      <td>astronaut|attacked by a plant|planet|senator|s...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>37000000.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.813675</td>\n",
       "      <td>2256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>Jason Lives: Friday the 13th Part VI</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>R</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Tom McLoughlin</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Tony Goldwyn</td>\n",
       "      <td>956.0</td>\n",
       "      <td>Ron Palillo</td>\n",
       "      <td>...</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "      <td>158.0</td>\n",
       "      <td>25332</td>\n",
       "      <td>actual animal killed|death|jason voorhees|slas...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.490686</td>\n",
       "      <td>262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>The Monuments Men</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>118.0</td>\n",
       "      <td>George Clooney</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bill Murray</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>Matt Damon</td>\n",
       "      <td>...</td>\n",
       "      <td>Drama|War</td>\n",
       "      <td>371.0</td>\n",
       "      <td>102248</td>\n",
       "      <td>art|art expert|nazi stolen art|soldier|world w...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>70000000.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.114737</td>\n",
       "      <td>1836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4217</th>\n",
       "      <td>The Missing Person</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Color</td>\n",
       "      <td>Unrated</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Noah Buschel</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Merritt Wever</td>\n",
       "      <td>529.0</td>\n",
       "      <td>Amy Ryan</td>\n",
       "      <td>...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1268</td>\n",
       "      <td>cellphone|detective|missing person|private det...</td>\n",
       "      <td>English</td>\n",
       "      <td>USA</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.011720</td>\n",
       "      <td>3649.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title    year  color content_rating  \\\n",
       "1757                    30 Minutes or Less  2011.0  Color              R   \n",
       "1382                          Space Chimps  2008.0  Color              G   \n",
       "3983  Jason Lives: Friday the 13th Part VI  1986.0  Color              R   \n",
       "598                      The Monuments Men  2014.0  Color          PG-13   \n",
       "4217                    The Missing Person  2009.0  Color        Unrated   \n",
       "\n",
       "      duration    director_name  director_fb          actor1  actor1_fb  \\\n",
       "1757      83.0  Ruben Fleischer        181.0  Bianca Kajlich      731.0   \n",
       "1382      81.0    Kirk De Micco         16.0    Cheryl Hines      541.0   \n",
       "3983      86.0   Tom McLoughlin         41.0    Tony Goldwyn      956.0   \n",
       "598      118.0   George Clooney          0.0     Bill Murray    13000.0   \n",
       "4217      95.0     Noah Buschel          8.0   Merritt Wever      529.0   \n",
       "\n",
       "                actor2  ...                                    genres  \\\n",
       "1757  Dilshad Vadsaria  ...                       Action|Comedy|Crime   \n",
       "1382    Kenan Thompson  ...  Adventure|Animation|Comedy|Family|Sci-Fi   \n",
       "3983       Ron Palillo  ...                           Horror|Thriller   \n",
       "598         Matt Damon  ...                                 Drama|War   \n",
       "4217          Amy Ryan  ...                                     Drama   \n",
       "\n",
       "     num_reviews  num_voted_users  \\\n",
       "1757       220.0            77935   \n",
       "1382        85.0             8860   \n",
       "3983       158.0            25332   \n",
       "598        371.0           102248   \n",
       "4217        66.0             1268   \n",
       "\n",
       "                                          plot_keywords language  country  \\\n",
       "1757  bank heist|bank robbery|heist gone wrong|pizza...  English  Germany   \n",
       "1382  astronaut|attacked by a plant|planet|senator|s...  English      USA   \n",
       "3983  actual animal killed|death|jason voorhees|slas...  English      USA   \n",
       "598   art|art expert|nazi stolen art|soldier|world w...  English      USA   \n",
       "4217  cellphone|detective|missing person|private det...  English      USA   \n",
       "\n",
       "          budget imdb_score       roi roi_rank  \n",
       "1757  28000000.0        6.1  1.323354   1579.0  \n",
       "1382  37000000.0        4.5  0.813675   2256.0  \n",
       "3983   3000000.0        5.9  6.490686    262.0  \n",
       "598   70000000.0        6.1  1.114737   1836.0  \n",
       "4217   1500000.0        6.2  0.011720   3649.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staff_picks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00f2bb",
   "metadata": {},
   "source": [
    "MODULE 3: ASSIGNING SUBSETS (LOGICAL UPDATES)\n",
    "Dataset: bikes.csv Context: We found a glitch. Rides under 60 seconds are likely errors and should be free ($0 cost). Also, we need to flag \"Commuter\" rides based on the day of the week.\n",
    "\n",
    "Topics: Assigning Subsets (.mask, .where), assign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1855df01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- subset Assignment Verification ---\n",
      "   tripduration  ride_cost ride_type           starttime\n",
      "0           993        1.5  Commuter 2013-06-28 19:01:00\n",
      "1           623        1.5  Commuter 2013-06-28 22:53:00\n",
      "2          1040        1.5   Leisure 2013-06-30 14:43:00\n",
      "3           667        1.5  Commuter 2013-07-01 10:05:00\n",
      "4           130        1.5  Commuter 2013-07-01 11:16:00\n",
      "\n",
      "Cost Distribution:\n",
      "ride_cost\n",
      "1.5    50089\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "bikes = pd.read_csv('../data/bikes.csv')\n",
    "\n",
    "# LOGIC:\n",
    "# 1. If tripduration < 60, Adjusted Cost = 0.\n",
    "# 2. If tripduration >= 60, Adjusted Cost = 1.50 (Standard Fee).\n",
    "# 3. Create a label 'Ride_Type': Commuter (Mon-Fri) or Leisure (Sat-Sun).\n",
    "\n",
    "# PRODUCTION CHAIN: Conditional Logic\n",
    "processed_rides = (\n",
    "    bikes\n",
    "    .assign(\n",
    "        # 1. DATETIME CONVERSION (Prerequisite)\n",
    "        starttime=lambda df_: pd.to_datetime(df_['starttime']),\n",
    "        \n",
    "        # 2. ASSIGNING SUBSETS (The .mask/.where Pattern)\n",
    "        # np.where(condition, value_if_true, value_if_false)\n",
    "        ride_cost=lambda df_: np.where(\n",
    "            df_['tripduration'] < 60, \n",
    "            0.00,   # Adjusted Cost = 0\n",
    "            1.50    # Standard Fee = 1.50\n",
    "        ),\n",
    "        ride_type=lambda df_: pd.Series(np.where(\n",
    "            df_['starttime'].dt.dayofweek < 5, \n",
    "            'Commuter', \n",
    "            'Leisure'\n",
    "        )).astype('category')\n",
    "        \n",
    "    )\n",
    "    # Filter to show the result\n",
    "    .loc[:, ['tripduration', 'ride_cost', 'ride_type', 'starttime']]\n",
    ")\n",
    "\n",
    "# VERIFICATION\n",
    "print(\"--- subset Assignment Verification ---\")\n",
    "print(processed_rides.head(5))\n",
    "print(\"\\nCost Distribution:\")\n",
    "print(processed_rides['ride_cost'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f72b4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_type\n",
       "Commuter    0.803071\n",
       "Leisure     0.196929\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_rides['ride_type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8623ffd",
   "metadata": {},
   "source": [
    "THE CURATOR ALGORITHM (Structure, Sorting & Ranking)\n",
    "Dataset: data/movie.csv Context: We are building a \"Streaming Recommendation Engine.\" We need to restructure the messy source file, insert new metrics, and rank movies to surface hidden gems. Sorting must be multi-dimensional (e.g., by Year then by Score).\n",
    "\n",
    "Topics: rename, drop, sort_values (multi-column), rank, nunique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f140653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Catalog Ranking Sample ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>director_name</th>\n",
       "      <th>title</th>\n",
       "      <th>gross</th>\n",
       "      <th>budget</th>\n",
       "      <th>profit_millions</th>\n",
       "      <th>rank_profit</th>\n",
       "      <th>rank_percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>Aaron Schneider</td>\n",
       "      <td>Get Low</td>\n",
       "      <td>9176553.0</td>\n",
       "      <td>7500000.0</td>\n",
       "      <td>1.676553</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>0.714700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>Aaron Seltzer</td>\n",
       "      <td>Date Movie</td>\n",
       "      <td>48546578.0</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>28.546578</td>\n",
       "      <td>848.0</td>\n",
       "      <td>0.004355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2862</th>\n",
       "      <td>Abel Ferrara</td>\n",
       "      <td>The Funeral</td>\n",
       "      <td>1227324.0</td>\n",
       "      <td>12500000.0</td>\n",
       "      <td>-11.272676</td>\n",
       "      <td>2892.0</td>\n",
       "      <td>0.517023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4334</th>\n",
       "      <td>Adam Carolla</td>\n",
       "      <td>Road Hard</td>\n",
       "      <td>105943.0</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>-1.394057</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>0.322776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>Adam Goldberg</td>\n",
       "      <td>I Love Your Work</td>\n",
       "      <td>2580.0</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>-1.647420</td>\n",
       "      <td>2226.0</td>\n",
       "      <td>0.143178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        director_name             title       gross      budget  \\\n",
       "3430  Aaron Schneider           Get Low   9176553.0   7500000.0   \n",
       "2156    Aaron Seltzer        Date Movie  48546578.0  20000000.0   \n",
       "2862     Abel Ferrara       The Funeral   1227324.0  12500000.0   \n",
       "4334     Adam Carolla         Road Hard    105943.0   1500000.0   \n",
       "4304    Adam Goldberg  I Love Your Work      2580.0   1650000.0   \n",
       "\n",
       "      profit_millions  rank_profit  rank_percentile  \n",
       "3430         1.676553       1820.0         0.714700  \n",
       "2156        28.546578        848.0         0.004355  \n",
       "2862       -11.272676       2892.0         0.517023  \n",
       "4334        -1.394057       2194.0         0.322776  \n",
       "4304        -1.647420       2226.0         0.143178  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PRODUCTION PIPELINE: Structure & Ranking\n",
    "# -----------------------------------------------------------------------------\n",
    "catalog_engine = (\n",
    "    pd.read_csv('../data/movie.csv')\n",
    "    \n",
    "    # 1. STRUCTURE METHODS: RENAMING & DROPPING\n",
    "    # Standard: Clean headers immediately to snake_case\n",
    "    .rename(columns=lambda c: c.strip().lower().replace(' ', '_'))\n",
    "    \n",
    "    # Standard: Drop columns that add noise (Vertical Filtering) and drop na for budget and gross\n",
    "    .drop(columns=['color', 'plot_keywords'], errors='ignore')\n",
    "    .dropna(subset=['gross', 'budget'])\n",
    "    \n",
    "    # 2. INSERTING DATA (Feature Engineering via .assign)\n",
    "    # Goal: Create a \"Profitability\" metric\n",
    "    .assign(\n",
    "        profit_millions = lambda df_: (df_['gross'] - df_['budget']) / 1_000_000,\n",
    "        # Goal: How does this movie compare to the whole catalog?\n",
    "        # 'dense': No gaps in rank (1, 2, 2, 3). Good for \"Top 10\" lists.\n",
    "        rank_profit = lambda df_: df_['profit_millions'].rank(method='dense', ascending=False),\n",
    "        \n",
    "        # 'pct': Percentile (0-1). Good for \"Top 1% of Movies\".\n",
    "        rank_percentile = lambda df_: df_['imdb_score'].rank(pct=True)\n",
    "    )\n",
    "    \n",
    "    # 3. MULTI-COLUMN SORTING\n",
    "    # Goal: Group by Director, then show their most profitable work first.\n",
    "    # Logic: Sort by 'director_name' (Ascending A-Z), then 'profit_millions' (Descending)\n",
    "    .sort_values(\n",
    "        by=['director_name', 'profit_millions'], \n",
    "        ascending=[True, False]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # 4. UNIQUENESS (Sanity Check)\n",
    "    # Ensure we don't recommend duplicates. \n",
    "    # keep='first' preserves the highest profit entry due to our previous sort.\n",
    "    .drop_duplicates(subset=['title'], keep='first')\n",
    ")\n",
    "\n",
    "# OUTPUT: Top 5 Highest Ranked Movies by Profit\n",
    "print(\"\\n--- Catalog Ranking Sample ---\")\n",
    "cols = ['director_name', 'title','gross','budget', 'profit_millions', 'rank_profit', 'rank_percentile']\n",
    "catalog_engine.loc[:, cols].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d9167c",
   "metadata": {},
   "source": [
    "THE OPS DASHBOARD (Aggregation & Subsets)\n",
    "Dataset: data/flights.csv Context: We manage airport operations. We need to create a \"Performance Report.\" This requires complex named aggregation (renaming columns while grouping) and assigning status labels based on logic (e.g., \"Severe Delay\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "758684ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Airline Performance Dashboard (Production Output) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>airline</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>arr_delay_clean</th>\n",
       "      <th>flight_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>LAS</td>\n",
       "      <td>IAH</td>\n",
       "      <td>100</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>PHX</td>\n",
       "      <td>515</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BOS</td>\n",
       "      <td>550</td>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>91</td>\n",
       "      <td>Severe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>DTW</td>\n",
       "      <td>BOS</td>\n",
       "      <td>600</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Delayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>LAS</td>\n",
       "      <td>EWR</td>\n",
       "      <td>600</td>\n",
       "      <td>1348</td>\n",
       "      <td>0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date airline origin dest  dep_time  arr_time  cancelled  air_time  \\\n",
       "0  2018-01-01      UA    LAS  IAH       100       547          0     134.0   \n",
       "1  2018-01-01      WN    DEN  PHX       515       720          0      91.0   \n",
       "2  2018-01-01      B6    JFK  BOS       550       657          0      39.0   \n",
       "3  2018-01-01      B6    DTW  BOS       600       754          0      79.0   \n",
       "4  2018-01-01      UA    LAS  EWR       600      1348          0     261.0   \n",
       "\n",
       "   distance  carrier_delay  weather_delay  nas_delay  security_delay  \\\n",
       "0    1222.0              0              0          0               0   \n",
       "1     602.0              0              0          0               0   \n",
       "2     187.0              0             83          8               0   \n",
       "3     632.0              0              0         19               0   \n",
       "4    2227.0              0              0          0               0   \n",
       "\n",
       "   late_aircraft_delay  arr_delay  arr_delay_clean flight_status  \n",
       "0                    0          0                0        Normal  \n",
       "1                    0          0                0        Normal  \n",
       "2                    0         91               91        Severe  \n",
       "3                    0         19               19       Delayed  \n",
       "4                    0          0                0        Normal  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. PRODUCTION PIPELINE: ROBUST FLIGHTS ANALYSIS\n",
    "# Architect's Note: The raw 'flights.csv' contains component delays (carrier, weather, etc.) \n",
    "# but lacks a pre-computed 'arr_delay' or 'flight_id'. We engineer them safely.\n",
    "ops_dashboard = (\n",
    "    pd.read_csv('../data/flights.csv')\n",
    "    \n",
    "    # A. Feature Engineering (Vectorized & Atomic)\n",
    "    .assign(\n",
    "        # Calculate total arrival delay from components (Safe Sum treats NaNs as 0)\n",
    "        arr_delay=lambda df_: (\n",
    "            df_.loc[:, ['carrier_delay', 'weather_delay', 'nas_delay', \n",
    "                        'security_delay', 'late_aircraft_delay']]\n",
    "               .sum(axis=1)\n",
    "        ),\n",
    "        \n",
    "        # Cap negative delays at 0 (Logic: Early arrival is not a negative penalty)\n",
    "        arr_delay_clean=lambda df_: df_['arr_delay'].clip(lower=0),\n",
    "        \n",
    "        # Status logic using np.select (The production standard for multiple conditions)\n",
    "        flight_status=lambda df_: np.select(\n",
    "            condlist=[\n",
    "                df_['arr_delay'] > 60,\n",
    "                df_['arr_delay'] > 15\n",
    "            ],\n",
    "            choicelist=['Severe', 'Delayed'],\n",
    "            default='Normal'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "    \n",
    "    # B. Named Aggregation (Explicit & Readable)\n",
    "ops_dashboard_agg = (   ops_dashboard.groupby('airline')\n",
    "    .agg(\n",
    "        total_flights   = ('date', 'count'),  # Use 'date' as a proxy for record count\n",
    "        avg_delay_min   = ('arr_delay_clean', 'mean'),\n",
    "        worst_delay_min = ('arr_delay_clean', 'max'),\n",
    "        \n",
    "        # Custom Metric: Percent of flights arriving > 15 mins late\n",
    "        pct_delayed     = ('arr_delay_clean', lambda x: (x > 15).mean())\n",
    "    )\n",
    "    \n",
    "    # C. Final Polish\n",
    "    .sort_values('pct_delayed', ascending=False)\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# 2. OUTPUT\n",
    "print(\"\\n--- Airline Performance Dashboard (Production Output) ---\")\n",
    "ops_dashboard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9334bd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_flights</th>\n",
       "      <th>avg_delay_min</th>\n",
       "      <th>worst_delay_min</th>\n",
       "      <th>pct_delayed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airline</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>F9</th>\n",
       "      <td>1141</td>\n",
       "      <td>20.69</td>\n",
       "      <td>494</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EV</th>\n",
       "      <td>171</td>\n",
       "      <td>22.36</td>\n",
       "      <td>812</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B6</th>\n",
       "      <td>3816</td>\n",
       "      <td>19.51</td>\n",
       "      <td>799</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MQ</th>\n",
       "      <td>373</td>\n",
       "      <td>14.17</td>\n",
       "      <td>191</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OH</th>\n",
       "      <td>257</td>\n",
       "      <td>16.46</td>\n",
       "      <td>337</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OO</th>\n",
       "      <td>2085</td>\n",
       "      <td>20.24</td>\n",
       "      <td>1498</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WN</th>\n",
       "      <td>4912</td>\n",
       "      <td>11.66</td>\n",
       "      <td>452</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YV</th>\n",
       "      <td>729</td>\n",
       "      <td>14.30</td>\n",
       "      <td>429</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VX</th>\n",
       "      <td>429</td>\n",
       "      <td>12.17</td>\n",
       "      <td>298</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UA</th>\n",
       "      <td>11882</td>\n",
       "      <td>14.26</td>\n",
       "      <td>1190</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AS</th>\n",
       "      <td>3244</td>\n",
       "      <td>10.13</td>\n",
       "      <td>362</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9E</th>\n",
       "      <td>1037</td>\n",
       "      <td>16.87</td>\n",
       "      <td>760</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>16779</td>\n",
       "      <td>12.45</td>\n",
       "      <td>1095</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YX</th>\n",
       "      <td>3200</td>\n",
       "      <td>12.49</td>\n",
       "      <td>851</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NK</th>\n",
       "      <td>2764</td>\n",
       "      <td>14.95</td>\n",
       "      <td>1351</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>13104</td>\n",
       "      <td>10.42</td>\n",
       "      <td>1084</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         total_flights  avg_delay_min  worst_delay_min  pct_delayed\n",
       "airline                                                            \n",
       "F9                1141          20.69              494         0.30\n",
       "EV                 171          22.36              812         0.28\n",
       "B6                3816          19.51              799         0.27\n",
       "MQ                 373          14.17              191         0.25\n",
       "OH                 257          16.46              337         0.23\n",
       "OO                2085          20.24             1498         0.23\n",
       "WN                4912          11.66              452         0.22\n",
       "YV                 729          14.30              429         0.21\n",
       "VX                 429          12.17              298         0.20\n",
       "UA               11882          14.26             1190         0.20\n",
       "AS                3244          10.13              362         0.20\n",
       "9E                1037          16.87              760         0.20\n",
       "AA               16779          12.45             1095         0.20\n",
       "YX                3200          12.49              851         0.20\n",
       "NK                2764          14.95             1351         0.18\n",
       "DL               13104          10.42             1084         0.15"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops_dashboard_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e9462589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>airline</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>air_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>LAS</td>\n",
       "      <td>IAH</td>\n",
       "      <td>100</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>PHX</td>\n",
       "      <td>515</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>JFK</td>\n",
       "      <td>BOS</td>\n",
       "      <td>550</td>\n",
       "      <td>657</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>DTW</td>\n",
       "      <td>BOS</td>\n",
       "      <td>600</td>\n",
       "      <td>754</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>UA</td>\n",
       "      <td>LAS</td>\n",
       "      <td>EWR</td>\n",
       "      <td>600</td>\n",
       "      <td>1348</td>\n",
       "      <td>0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>2227.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65918</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>WN</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2200</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>946.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65919</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>B6</td>\n",
       "      <td>SEA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2215</td>\n",
       "      <td>625</td>\n",
       "      <td>0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2422.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65920</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>B6</td>\n",
       "      <td>PHX</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2234</td>\n",
       "      <td>509</td>\n",
       "      <td>0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>2153.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65921</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>UA</td>\n",
       "      <td>SFO</td>\n",
       "      <td>EWR</td>\n",
       "      <td>2300</td>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65922</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>DFW</td>\n",
       "      <td>2315</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1660.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65923 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date airline origin dest  dep_time  arr_time  cancelled  \\\n",
       "0      2018-01-01      UA    LAS  IAH       100       547          0   \n",
       "1      2018-01-01      WN    DEN  PHX       515       720          0   \n",
       "2      2018-01-01      B6    JFK  BOS       550       657          0   \n",
       "3      2018-01-01      B6    DTW  BOS       600       754          0   \n",
       "4      2018-01-01      UA    LAS  EWR       600      1348          0   \n",
       "...           ...     ...    ...  ...       ...       ...        ...   \n",
       "65918  2018-12-31      WN    ATL  BOS      2200        30          0   \n",
       "65919  2018-12-31      B6    SEA  JFK      2215       625          0   \n",
       "65920  2018-12-31      B6    PHX  JFK      2234       509          0   \n",
       "65921  2018-12-31      UA    SFO  EWR      2300       712          0   \n",
       "65922  2018-12-31      AS    SEA  DFW      2315       502          0   \n",
       "\n",
       "       air_time  distance  carrier_delay  weather_delay  nas_delay  \\\n",
       "0         134.0    1222.0              0              0          0   \n",
       "1          91.0     602.0              0              0          0   \n",
       "2          39.0     187.0              0             83          8   \n",
       "3          79.0     632.0              0              0         19   \n",
       "4         261.0    2227.0              0              0          0   \n",
       "...         ...       ...            ...            ...        ...   \n",
       "65918     116.0     946.0              0              0          0   \n",
       "65919     282.0    2422.0              0              0          0   \n",
       "65920     233.0    2153.0              0              0          0   \n",
       "65921     265.0    2565.0             20              0          0   \n",
       "65922     210.0    1660.0              3              0          3   \n",
       "\n",
       "       security_delay  late_aircraft_delay  \n",
       "0                   0                    0  \n",
       "1                   0                    0  \n",
       "2                   0                    0  \n",
       "3                   0                    0  \n",
       "4                   0                    0  \n",
       "...               ...                  ...  \n",
       "65918               0                    0  \n",
       "65919               0                    0  \n",
       "65920               0                    0  \n",
       "65921               0                    0  \n",
       "65922               0                   26  \n",
       "\n",
       "[65923 rows x 14 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/flights.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "abb27f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Market Extremes (Source: MSFT) ---\n",
      "Worst Crash: 2019-10-18 (-1.00%)\n",
      "Best Rally : 2019-10-09  (1.26%)\n",
      "\n",
      "--- Interpolation Comparison Audit ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msft</th>\n",
       "      <th>price_ffill</th>\n",
       "      <th>price_interp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-08</th>\n",
       "      <td>135.67</td>\n",
       "      <td>135.67</td>\n",
       "      <td>135.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>135.67</td>\n",
       "      <td>137.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-10</th>\n",
       "      <td>139.10</td>\n",
       "      <td>139.10</td>\n",
       "      <td>139.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>139.10</td>\n",
       "      <td>139.923333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>139.10</td>\n",
       "      <td>140.746667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-15</th>\n",
       "      <td>141.57</td>\n",
       "      <td>141.57</td>\n",
       "      <td>141.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              msft  price_ffill  price_interp\n",
       "date                                         \n",
       "2019-10-08  135.67       135.67    135.670000\n",
       "2019-10-09     NaN       135.67    137.385000\n",
       "2019-10-10  139.10       139.10    139.100000\n",
       "2019-10-11     NaN       139.10    139.923333\n",
       "2019-10-14     NaN       139.10    140.746667\n",
       "2019-10-15  141.57       141.57    141.570000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. PRODUCTION-GRADE FINANCIAL PIPELINE\n",
    "# Standard: We perform header standardization and datetime conversion immediately.\n",
    "# Standard: We pick 'msft' as the primary price proxy (as 'price' is not in the source).\n",
    "market_analysis = (\n",
    "    pd.read_csv('../data/stocks/sample_missing.csv')\n",
    "    # A. Ingestion & Standardization\n",
    "    .rename(columns=lambda c: c.strip().lower())\n",
    "    .assign(date=lambda df_: pd.to_datetime(df_['date']))\n",
    "    .sort_values('date')\n",
    "    .set_index('date')\n",
    "    \n",
    "    # B. Missing Data Restoration (Physics of Markets)\n",
    "    # Using 'msft' as the target column found in the dataset.\n",
    "    .assign(\n",
    "        # Forward fill: \"Price remains unchanged until the next transaction.\"\n",
    "        price_ffill=lambda df_: df_['msft'].ffill(),\n",
    "        \n",
    "        # Linear Interpolation: \"Estimates price movement across gaps.\"\n",
    "        # limit_direction='both' ensures gaps at the file boundaries are handled.\n",
    "        price_interp=lambda df_: df_['msft'].interpolate(method='linear', limit_direction='both')\n",
    "    )\n",
    "    \n",
    "    # C. Financial Feature Engineering (Vectorized)\n",
    "    .assign(\n",
    "        # diff(): Absolute dollar change from previous period.\n",
    "        dollar_change=lambda df_: df_['price_interp'].diff(),\n",
    "        \n",
    "        # pct_change(): Relative daily return (Standard for volatility/crash analysis).\n",
    "        daily_return=lambda df_: df_['price_interp'].pct_change()\n",
    "    )\n",
    ")\n",
    "\n",
    "# 2. EXTREME VALUE EXTRACTION\n",
    "# Use .idxmin()/.idxmax() on the Series for precise label (Date) extraction.\n",
    "# Note: For time series with unique daily dates, this is the precision standard.\n",
    "worst_crash_date = market_analysis['daily_return'].idxmin()\n",
    "best_rally_date  = market_analysis['daily_return'].idxmax()\n",
    "\n",
    "# 3. PRODUCTION REPORTING\n",
    "print(f\"--- Market Extremes (Source: MSFT) ---\")\n",
    "# Accessing scalar values via .at for high-performance retrieval in reports.\n",
    "#df.at[row_label, column_label] syntax for .at\n",
    "print(f\"Worst Crash: {worst_crash_date.date()} ({market_analysis.at[worst_crash_date, 'daily_return']:.2%})\")\n",
    "print(f\"Best Rally : {best_rally_date.date()}  ({market_analysis.at[best_rally_date, 'daily_return']:.2%})\")\n",
    "\n",
    "print(\"\\n--- Interpolation Comparison Audit ---\")\n",
    "# Precision Selection: .loc with explicit column list\n",
    "market_analysis.loc[:, ['msft', 'price_ffill', 'price_interp']].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4dd237c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-10-18 00:00:00')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_analysis['daily_return'].idxmin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea2fd8",
   "metadata": {},
   "source": [
    "THE HR AUDITOR\n",
    "\n",
    "Focus: Structure, Sorting, and Advanced Ranking. \n",
    "\n",
    "Dataset: data/sf_employee_compensation.csv \n",
    "\n",
    "Business Goal: Audit the city's payroll. We need to restructure the messy raw file, insert categorization logic, and rank employees to find the top earners within each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7dee3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Payroll Leaderboard (Top 5) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 9951 to 11670\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype   \n",
      "---  ------              --------------  -----   \n",
      " 0   year                1000 non-null   int64   \n",
      " 1   organization_group  1000 non-null   category\n",
      " 2   job                 1000 non-null   category\n",
      " 3   salaries            1000 non-null   float64 \n",
      " 4   overtime            1000 non-null   float64 \n",
      " 5   other_salaries      1000 non-null   float64 \n",
      " 6   retirement          1000 non-null   float64 \n",
      " 7   health_and_dental   1000 non-null   float64 \n",
      " 8   other_benefits      1000 non-null   float64 \n",
      " 9   total_benefits      1000 non-null   float64 \n",
      " 10  total_compensation  1000 non-null   float64 \n",
      " 11  total_benefits_k    1000 non-null   float64 \n",
      " 12  city_rank           1000 non-null   float64 \n",
      " 13  comp_percentile     1000 non-null   float64 \n",
      " 14  standard_rank       1000 non-null   float64 \n",
      "dtypes: category(2), float64(12), int64(1)\n",
      "memory usage: 147.4 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. PRODUCTION INGESTION\n",
    "# Architect's Note: We removed the 'drop' step for non-existent columns (year_type, union_code)\n",
    "# to keep the pipeline clean and error-free.\n",
    "emp_raw = (\n",
    "    pd.read_csv('../data/sf_employee_compensation.csv')\n",
    "    .sample(1000, random_state=42)\n",
    "    # Standardize Headers: 'organization group' -> 'organization_group'\n",
    "    .rename(columns=lambda c: c.strip().lower().replace(' ', '_'))\n",
    ")\n",
    "\n",
    "# 2. ANALYSIS PIPELINE\n",
    "hr_audit = (\n",
    "    emp_raw\n",
    "    # FEATURE ENGINEERING: Constructing Missing Metrics (Atomic & Vectorized)\n",
    "    # We must calculate totals before we can rank or sort by them.\n",
    "    .assign(\n",
    "        # Robust Summation: .sum(axis=1) treats NaNs as 0, avoiding data loss.\n",
    "        total_benefits=lambda df_: df_[[\n",
    "            'retirement', 'health_and_dental', 'other_benefits'\n",
    "        ]].sum(axis=1),\n",
    "        \n",
    "        # Calculate Base Total Comp first\n",
    "        total_compensation=lambda df_: df_[[\n",
    "            'salaries', 'overtime', 'other_salaries'\n",
    "        ]].sum(axis=1)\n",
    "    )\n",
    "    # Add Total Benefits to Total Comp (Chained for dependency)\n",
    "    .assign(\n",
    "        total_compensation=lambda df_: df_['total_compensation'] + df_['total_benefits'],\n",
    "        total_benefits_k=lambda df_: df_['total_benefits'] / 1000\n",
    "    )\n",
    "    \n",
    "    # TYPE OPTIMIZATION\n",
    "    # Converting low-cardinality strings (Org, Job) to categories saves memory.\n",
    "    # Note: Source column is 'job', not 'job_family'.\n",
    "    .assign(\n",
    "        organization_group=lambda df_: df_['organization_group'].astype('category'),\n",
    "        job=lambda df_: df_['job'].astype('category')\n",
    "    )\n",
    "    \n",
    "    # MULTI-COLUMN SORTING\n",
    "    .sort_values(\n",
    "        by=['organization_group', 'total_compensation'], \n",
    "        ascending=[True, False]\n",
    "    )\n",
    "    \n",
    "    # ADVANCED RANKING (Vectorized)\n",
    "    .assign(\n",
    "        # Dense Rank: 1, 2, 2, 3 (No gaps, good for leaderboards)\n",
    "        city_rank=lambda df_: df_['total_compensation'].rank(method='dense', ascending=False),\n",
    "        \n",
    "        # Percentile: 0.0 to 1.0 (Good for distribution analysis)\n",
    "        comp_percentile=lambda df_: df_['total_compensation'].rank(pct=True),\n",
    "        \n",
    "        # Standard Rank: 1, 2, 2, 4 (Standard competition ranking)\n",
    "        standard_rank=lambda df_: df_['total_compensation'].rank(method='min', ascending=False)\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. REPORTING\n",
    "print(\"\\n--- Payroll Leaderboard (Top 5) ---\")\n",
    "# Precision Selection: Using the correct column 'job' instead of 'job_family'\n",
    "cols_to_show = ['organization_group', 'job', 'total_compensation', 'city_rank', 'comp_percentile']\n",
    "hr_audit.loc[:, cols_to_show].head(5)\n",
    "\n",
    "\n",
    "#print(\"\\n--- Structure Audit ---\")\n",
    "hr_audit.info( memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c9772398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organization_group</th>\n",
       "      <th>job</th>\n",
       "      <th>total_compensation</th>\n",
       "      <th>city_rank</th>\n",
       "      <th>comp_percentile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>Community Health</td>\n",
       "      <td>Nurse Manager</td>\n",
       "      <td>307384.56</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23111</th>\n",
       "      <td>Community Health</td>\n",
       "      <td>Senior Physician Specialist</td>\n",
       "      <td>298402.09</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48224</th>\n",
       "      <td>Community Health</td>\n",
       "      <td>Clinical Nurse Specialist</td>\n",
       "      <td>272962.98</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>Community Health</td>\n",
       "      <td>Diagnostic Imaging Tech III</td>\n",
       "      <td>262742.46</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941</th>\n",
       "      <td>Community Health</td>\n",
       "      <td>Senior Physician Specialist</td>\n",
       "      <td>256384.52</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      organization_group                          job  total_compensation  \\\n",
       "9951    Community Health                Nurse Manager           307384.56   \n",
       "23111   Community Health  Senior Physician Specialist           298402.09   \n",
       "48224   Community Health    Clinical Nurse Specialist           272962.98   \n",
       "3156    Community Health  Diagnostic Imaging Tech III           262742.46   \n",
       "1941    Community Health  Senior Physician Specialist           256384.52   \n",
       "\n",
       "       city_rank  comp_percentile  \n",
       "9951         2.0            0.999  \n",
       "23111        5.0            0.996  \n",
       "48224       12.0            0.989  \n",
       "3156        13.0            0.988  \n",
       "1941        18.0            0.983  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_audit.loc[:, cols_to_show].head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
